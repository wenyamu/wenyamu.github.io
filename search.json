[{"title":"python ffmpeg","url":"/979063cb.html","content":"77777","tags":["ffmpeg"],"categories":["python"]},{"title":"python2与python3共存","url":"/b6550676.html","content":">大多数情况下，系统已经安装了python，并且默认的 python 版本是 /usr/bin/python2.7\n```\nroot@nj:~# python -V\nPython 2.7.18\nroot@nj:~# python2 -V\nPython 2.7.18\nroot@nj:~# python2.7 -V\nPython 2.7.18\n```\n<!-- more -->\n>在/usr/bin/目录下可以看到有多个python程序文件，python命令默认指向的是 python2\n```\nroot@nj:~# ls -al /usr/bin/ | grep \"python\"\npython -> python2\npython2 -> python2.7\npython2.7\npython3 -> python3.9\npython3.9\n```\n>如果没有安装 python3.9，执行以下命令安装\n```bash\napt update && apt install -y python3.9\n```\n>python3.9版本的使用方法\n```\nroot@nj:~# python3 -V\nPython 3.9.2\nroot@nj:~# python3.9 -V\nPython 3.9.2\n```\n>到这里，系统中就安装了python2 和 python3 两个版本，分别执行 python2.7 和 python3.9 两个命令就可以使用指定的版本，但是使用python命令默认的还是python2.7，如何切换到python3.9呢？\n```\nroot@nj:~# python -V\nPython 2.7.18\n```\n```bash\n#将/usr/bin/python2.7优先级设置为1\nupdate-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n\n#将/usr/bin/python3.9优先级设置为2\nupdate-alternatives --install /usr/bin/python python /usr/bin/python3.9 2\n\n#使用以下命令切换版本，输入1或2等数字切换\nupdate-alternatives --config python\n```\n\n>使用 update-alternatives 命令之后，在/usr/bin/目录下可以看到python的指向位置\n```\nroot@nj:~# ls -al /usr/bin/ | grep \"python\"\npython -> /etc/alternatives/python\npython2 -> python2.7\npython2.7\npython3 -> python3.9\npython3.9\n```\n>在 /etc/alternatives/ 目录下查看python指向位置\n```\nroot@nj:~# ls -al /etc/alternatives/ | grep \"python\"\npython -> /usr/bin/python3.9\n```\n\n>切换python2.7与python3.9的效果展示\n```\n#当未设置python不同版本的优先级时，执行切换命令返回错误提示\nroot@nj:~# update-alternatives --config python\nupdate-alternatives: error: no alternatives for python\n\n#设置python不同版本的优先级\nroot@nj:~# update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\nupdate-alternatives: using /usr/bin/python2.7 to provide /usr/bin/python (python) in auto mode\nroot@nj:~# update-alternatives --install /usr/bin/python python /usr/bin/python3.9 2\nupdate-alternatives: using /usr/bin/python3.9 to provide /usr/bin/python (python) in auto mode\n\n#切换\nroot@nj:~# update-alternatives --config python\nThere are 2 choices for the alternative python (providing /usr/bin/python).\n\n  Selection    Path                Priority   Status\n------------------------------------------------------------\n* 0            /usr/bin/python3.9   2         auto mode\n  1            /usr/bin/python2.7   1         manual mode\n  2            /usr/bin/python3.9   2         manual mode\n\nPress <enter> to keep the current choice[*], or type selection number: 1\nupdate-alternatives: using /usr/bin/python2.7 to provide /usr/bin/python (python) in manual mode\nroot@nj:~# python -V\nPython 2.7.18\n\n#1 python2.7\n#2 python3.9\n\n```\n\n>pip如何共存呢，安装python3.9后默认指向的是pip3，并且pip2命令是不存在的\n```\nroot@nj:~# pip -V\npip 23.1.2 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\nroot@nj:~# pip3 -V\npip 23.1.2 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\nroot@nj:~# pip3.9 -V\npip 23.1.2 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n\nroot@nj:~# pip2 -V\n-bash: pip2: command not found\nroot@nj:~# pip2.7 -V\n-bash: pip2.7: command not found\n```\n>安装pip2\n```bash\nwget https://bootstrap.pypa.io/pip/2.7/get-pip.py && \\\npython2.7 get-pip.py\n```\n>这时pip2和pip3共存，但是默认的版本变成了pip2，并且pip默认版本不会根据python版本的切换而变化\n```\nroot@nj:~# python -V\nPython 3.9.2\nroot@nj:~# pip -V\npip 20.3.4 from /usr/local/lib/python2.7/dist-packages/pip (python 2.7)\n\nroot@nj:~# pip2 -V\npip 20.3.4 from /usr/local/lib/python2.7/dist-packages/pip (python 2.7)\nroot@nj:~# pip2.7 -V\npip 20.3.4 from /usr/local/lib/python2.7/dist-packages/pip (python 2.7)\n\nroot@nj:~# pip3 -V\npip 23.1.2 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\nroot@nj:~# pip3.9 -V\npip 23.1.2 from /usr/local/lib/python3.9/dist-packages/pip (python 3.9)\n\n```","tags":["python"],"categories":["python"]},{"title":"frp内网穿透","url":"/d87f7e0c.html","content":"\n## 查看系统cpu架构\n> 如果输出结果中包含 x86_64 则表示系统的 CPU 架构是 AMD64\n> 如果输出结果中包含 aarch64 或 arm64，则表示系统的 CPU 架构是 ARM64\n```bash\nlscpu | grep Architecture\n```\n<!-- more -->\n## 公网服务器下载frp\n```bash\nwget https://github.com/fatedier/frp/releases/download/v0.58.1/frp_0.58.1_linux_amd64.tar.gz\n```\n## 解压命令\n```bash\ntar -zxvf frp_0.58.1_linux_amd64.tar.gz\n```\n## 编辑frps.toml文件\n```bash\ncd frp_0.58.1_linux_amd64 && nano frps.toml\n```\n\n## frps.toml\n```toml\n######################################################################\n# 公网服务器开启端口: 6000, 7000, 6080, 6081, 6082, 6443, 8080, 8443 #\n######################################################################\n\n# 官网 https://gofrp.org/zh-cn/docs/overview/\n\n# 服务端frps与客户端frpc绑定进行通信的端口(此端口只作为两者通信用，具体应用还需要开启相应的端口)\nbindPort = 7000\n\n### http 或 https 代理\n### 如果 公网服务器的 80 和 443 已经被占用，只能指定其它端口，只是在访问的时候url后面要加上相应的端口，比如：\n### http://test.abc.com:8080 或 https://demo.abc.com:8443\nvhostHTTPPort = 8080\nvhostHTTPSPort = 8443\n```\n\n## 局域网设备下载frp\n```bash\nwget https://github.com/fatedier/frp/releases/download/v0.58.1/frp_0.58.1_linux_arm64.tar.gz\n```\n## 解压命令\n```bash\ntar -zxvf frp_0.58.1_linux_arm64.tar.gz\n```\n\n## 编辑frpc.toml文件\n```bash\ncd frp_0.58.1_linux_arm64 && nano frpc.toml\n```\n## frpc.toml\n> 通用部分配置\n```toml\n######################################################################\n# 公网服务器开启端口: 6000, 7000, 6080, 6081, 6082, 6443, 8080, 8443 #\n######################################################################\n\n# 官网 https://gofrp.org/zh-cn/docs/overview/\n\n# 公网服务器ip\nserverAddr = \"88.218.238.208\"\n# 服务端frps与客户端frpc绑定进行通信的端口(此端口只作为两者通信用，具体应用还需要开启相应的端口)\nserverPort = 7000\n```\n> 远程 ssh 配置\n```toml\n# 远程 ssh 配置\n# 88.218.238.208:6000 相当于在局域网中 ip:22\n[[proxies]]\nname = \"ssh\"\ntype = \"tcp\"\nlocalIP = \"127.0.0.1\"\nlocalPort = 22\nremotePort = 6000\n```\n> http 或 https 代理配置\n\n```toml\n### 路由及自定义域名设置 https://gofrp.org/zh-cn/docs/features/http-https/route/\n### 按照以下的示例配置后，w1.abc.com 这个域名下所有以 /news 以及 /about 作为前缀的 URL 请求\n### 都会被转发到 http81，其余的请求会被转发到 http80。\n[[proxies]]\nname = \"http80\"\ntype = \"http\"\nlocalPort = 80\n## 原理 http://w1.abc.com:8080/ --->>> 127.0.0.1:80/\ncustomDomains = [\"w1.abc.com\"]\nlocations = [\"/\"]\n\n[[proxies]]\nname = \"http81\"\ntype = \"http\"\nlocalPort = 81\n## 原理 http://w1.abc.com:8080/news/ --->>> 127.0.0.1:81/news/\ncustomDomains = [\"w1.abc.com\"]\nlocations = [\"/news\", \"/about\"]\n### 用户名和密码的访问设置，访问时要验证才能查看页面，仅对 http 代理有效\n#httpUser = \"demo\"\n#httpPassword = \"1234\"\n\n### https 自定义域名设置，https 会提示不安全，你可以强制访问。\n[[proxies]]\nname = \"https443\"\ntype = \"https\"\nlocalPort = 443\n## 原理 https://w1.abc.com:8443 --->>> 127.0.0.1:443\ncustomDomains = [\"w1.abc.com\"]\n\n[[proxies]]\nname = \"https444\"\ntype = \"https\"\nlocalPort = 444\n## 原理 https://w2.abc.com:8443 --->>> 127.0.0.1:444\ncustomDomains = [\"w2.abc.com\"]\n```\n> tcp 代理配置\n> 注意：每个tcp代理的 remotePort 不能一样\n```toml\n### 开启公网服务器端口 6080、6443\n[[proxies]]\nname = \"tcp80\"\ntype = \"tcp\"\nlocalIP = \"127.0.0.1\"\nlocalPort = 80\n## 原理 http://88.218.238.208:6080 --->>> 127.0.0.1:80\nremotePort = 6080\n\n[[proxies]]\nname = \"tcp443\"\ntype = \"tcp\"\nlocalIP = \"127.0.0.1\"\nlocalPort = 443\n## 原理 https://88.218.238.208:6443 --->>> 127.0.0.1:443\nremotePort = 6443\n```\n> frp实现的负载均衡\n```toml\n### 注意：\n### 正常情况下，每个tcp代理的 remotePort 不能一样。但是负载均衡时，远程端口要一样(端口不同就无法实现负载均衡了)\n### group 值相同的代理，会以轮询的方式实现负载均衡\n### groupKey 为可选项，如果有，则值必须要相同\n### http://88.218.238.208:6081 --->>> 127.0.0.1:81、127.0.0.1:82\n### 查看效果时，要有耐心，多刷新几次（快速点击F5键），不然看不到负载均衡切换效果\n[[proxies]]\nname = \"tcp81\"\ntype = \"tcp\"\nlocalIP = \"127.0.0.1\"\nlocalPort = 81\n## 原理 http://88.218.238.208:6081 --->>> 127.0.0.1:81\nremotePort = 6081\nloadBalancer.group = \"web\"\n#loadBalancer.groupKey = \"str123\"\n\n[[proxies]]\nname = \"tcp82\"\ntype = \"tcp\"\nlocalIP = \"127.0.0.1\"\nlocalPort = 82\n## 原理 http://88.218.238.208:6081 --->>> 127.0.0.1:82\nremotePort = 6081\nloadBalancer.group = \"web\"\n#loadBalancer.groupKey = \"str123\"\n```\n> http 转 https 插件\n```toml\n#### http 转 https, 适用于公网服务器 443 端口没有占用的情况\n#### 如果 公网服务器 443 端口被占用，可以指定 其它端口，但是访问的时候需要加上端口，比如 https://demo.abc.com:8443\n\n[[proxies]]\nname = \"plugin_htts2http\"\ntype = \"https\"\ncustomDomains = [\"test.abc.com\"]\n[proxies.plugin]\ntype = \"https2http\"\nlocalAddr = \"127.0.0.1:80\"\n# HTTPS 证书配置（局域网客户端上的证书路径）\ncrtPath = \"/www1/web/ssl/abc.com/cert.pem\"\nkeyPath = \"/www1/web/ssl/abc.com/key.pem\"\n\n```\n> Unix 域套接字插件\n```toml\n### Unix 域套接字插件\n[[proxies]]\nname = \"plugin_unix_domain_socket\"\ntype = \"tcp\"\nremotePort = 6082\n### http://88.218.238.208:6082/version 返回 `docker version` 命令查询到的版本信息\n[proxies.plugin]\ntype = \"unix_domain_socket\"\n### Unix 域套接字路径\nunixPath = \"/var/run/docker.sock\"\n```\n> 以上 frpc.toml 文件\n\n## 运行\n```bash\n#公网服务器开启frps命令\n./frps -c ./frps.toml\n\n#局域网设备开启frpc命令\n./frpc -c ./frpc.toml\n```"},{"title":"openssl 生成自签名证书","url":"/5e3d4120.html","content":"## 生成自签名证书(不能用于生产环境)\n{% note info  %}\n其中的目录 /root/ssl 必须事先存在\n\n{% endnote %}\n\n```sh\nopenssl req -x509 -nodes \\\n-days 365 \\\n-newkey rsa:2048 \\\n-keyout /root/ssl/nginx.key \\\n-out /root/ssl/nginx.crt\n```\n<!-- more -->\n{% note success %}\n**参数说明**\n`-req` 请求处理器，用于处理SSL证书的请求。\n`-x509` 指定生成一个X509格式的SSL证书。\n`-nodes` 指定不对生成的SSL证书进行加密。\n`-days 365` 指定证书的有效期为365天\n`-newkey rsa:2048` 创建一个新的2048位的密钥\n`-keyout /root/ssl/nginx.key` 私钥文件\n`-out /root/ssl/nginx.crt` 证书文件\n{% endnote %}\n\n## 查看证书(网站的ssl证书也可以使用此方法)\n```sh\n#查看证书的起始日期和过期日期\nopenssl x509 -in /root/ssl/nginx.crt -noout -dates\n```\n> 返回结果\nnotBefore=Mar 25 18:16:56 2024 GMT\nnotAfter=Mar 25 18:16:56 2025 GMT\n\n```sh\n# 查看证书的过期日期\nopenssl x509 -enddate -noout -in /root/ssl/nginx.crt\n```\n> 返回结果\nnotAfter=Mar 25 18:16:56 2025 GMT\n\n## 检查证书(网站的ssl证书也可以使用此方法)\n>python脚本,检查证书是否过期\n```python\n#!/usr/bin/env python3\n\nimport subprocess\nimport datetime\n\ndomain = \"abc.com\"\ntoday = datetime.datetime.today() # 2024-05-30 04:28:26.287235\n\np1 = subprocess.Popen([\"openssl\", \"x509\", \"-noout\", \"-enddate\", \"-in\", \"/path/ssl/%s/cert.pem\" % domain], stdout=subprocess.PIPE)\np2 = subprocess.Popen([\"grep\", \"notAfter\"], stdin=p1.stdout, stdout=subprocess.PIPE)\np1.stdout.close()\noutput = p2.communicate()[0].strip()[9:].decode('utf-8') # Aug 27 06:57:08 2024 GMT\n\nexpire_date = datetime.datetime.strptime(output, '%b %d %H:%M:%S %Y %Z') # 2024-08-27 06:57:08\ndelta = expire_date - today # 89 days, 2:31:50.550693\n#print(delta.days)  # 89\n\nif delta.days > 7:\n    print(\"你的 %s 证书将在 %d 天后过期！\" % (domain, delta.days))\nelif delta.days <= 0:\n    print(f\"你的 {domain} 证书已过期！\")\nelse:\n    print(f\"你的 {domain} 证书将在 {delta.days} 天内过期，请尽快更新证书！\")\n```\n> shell脚本,检查证书是否过期\n```bash\n#!/bin/bash\n\n# 使用openssl检查证书文件是否过期\n# 替换下面的'/path/to/certificate.pem'为您的证书文件路径\n\nEXPIRE_DATE=`openssl x509 -enddate -noout -in /path/to/certificate.pem | sed 's/notAfter=//'`\nCURRENT_DATE=`date +%s`\nEXPIRE_DATE_SEC=`date +%s -d \"$EXPIRE_DATE\"`\n\nif [ \"$EXPIRE_DATE_SEC\" -lt \"$CURRENT_DATE\" ]; then\n    echo \"SSL证书已过期\"\nelse\n    echo \"SSL证书未过期,有效期至 $EXPIRE_DATE\"\nfi\n\n```","tags":["ssl","openssl"],"categories":["linux"]},{"title":"docker容器目录映射研究","url":"/b9078a91.html","content":"## 一、通过 docker 命令创建容器\n\n>方法一: 不映射目录\n访问 `http://0.0.0.0:80`时，页面正常可浏览(前提是`/usr/share/nginx/html`目录下有可访问的web页)。\n\n```bash\n#方法一\ndocker run -itd \\\n-p 80:80 \\\n--name diy \\\nnginx\n```\n<!-- more -->\n\n\n>方法二:\n1, 当`/root/diy_html`目录有内容时,宿主机目录覆盖容器目录.访问 `http://0.0.0.0:80`时,页面正常可浏览.\n2, 当`/root/diy_html`目录不存在或者无内容时,容器目录会变为空.访问 `http://0.0.0.0:80`时，返回 `403 Forbidden`.\n\n```bash\n#方法二\ndocker run -itd \\\n-p 80:80 \\\n-v /root/diy_html:/usr/share/nginx/html \\\n--name diy \\\nnginx\n```\n\n>方法三:\n1, 如果 `diy_html` 有数据，宿主机覆盖容器。\n2, 如果 `diy_html` 没有数据，容器覆盖宿主机。\n访问 `http://0.0.0.0:80`时，页面正常可浏览。\n\n>`-v diy_html:/usr/share/nginx/html`相当于执行 `docker volume create diy_html` 在宿主机上创建目录 `/var/lib/docker/volumes/diy_html/_data` 与容器目录`/usr/share/nginx/html`映射\n\n```bash\n#方法三\ndocker run -itd \\\n-p 80:80 \\\n-v diy_html:/usr/share/nginx/html \\\n--name diy \\\nnginx\n```\n{% note success %}\n以上宿主机的目录数据不受容器的停止或删除的影响，数据会一直存在。\n{% endnote %}\n\n\n## 二、通过 docker compose 创建容器\n\n```yml compose.yml\n#version: '3'\nvolumes:\n  nginxhtmldata:\n    #相当于执行 docker volume create nginx_html\n    #注意：此设置当容器停止或删除，/var/lib/docker/volumes/nginx_html/_data 目录会变为空\n    name: nginx_html\n    driver: local\n    driver_opts:\n      o: bind\n      type: none\n      #注意：此设置需要宿主机目录要事先存在（此目录不会因为容器的停止与删除而被清空）\n      device: /www/nginx/html\n\nservices:\n    nginx:\n        image: nginx\n        hostname: nginxHost\n        # 映射端口 【宿主机端口:容器端口】\n        ports:\n            - \"80:80\"\n        # 容器名称\n        container_name: my_nginx\n        restart: always\n        # 相当于 docker run -i\n        stdin_open: true\n        # 相当于 docker run -t\n        tty: true\n        # 目录挂载 【宿主机目录:容器目录】\n        volumes:\n            # 方法一：\n            # 最常用的形式\n            # 注意：宿主机目录会自动生成，如果目录没有内容，则容器目录也会被清空。\n            - /www/web1:/var/www/html1\n\n            # 方法二：\n            # 效果等同于方法一，不同的是宿主机 /www/web2 目录要提前创建\n            - type: bind\n              source: /www/web2\n              target: /var/www/html2\n\n            # 方法三：\n            # 有以下两种情况和注意事项：\n            # 1、如果宿主机目录无内容，容器的目录 覆盖 宿主机目录\n            # 2、如果宿主机目录有内容，宿主机目录 覆盖 容器的目录\n            - type: volume\n              source: nginxhtmldata # 上面定义的宿主机目录（此目录要提前创建）\n              target: /usr/share/nginx/html # 容器目录\n            \n            # 方法四：\n            # 是方法三的简写形式\n            - nginxhtmldata:/usr/share/nginx/html\n\n```\n\n```bash\n#创建容器\ndocker compose -f compose.yml up -d\n```\n{% note info %}\n1, 方法三和方法四，当容器停止或删除时\n`/var/lib/docker/volumes/nginx_html/_data` 数据被清空（这与通过docker命令创建容器的情况不同）\n`/www/nginx/html` 数据会一直存在\n2, 方法一、方法二 不受容器停止或删除的影响，宿主机数据一直存在。\n{% endnote %}\n","tags":["docker"],"categories":["linux"]},{"title":"acme.sh 申请 ssl 域名证书","url":"/cce1856a.html","content":"## 单独以 docker 守护进程运行 acme.sh 程序\n> `/localhost/out` 生成的原始证书的目录\n\n> `/localhost/ssl` 通过 `acme.sh --install-cert` 复制和转换证书格式后存放的目录(nginx 配置文件引用的 ssl 证书目录) 比如：`/localhost/ssl/abc.com`\n\n> `/localhost/web` 存放网站页面的目录，比如：`/localhost/web/abc.com` 存放的是网站 abc.com 的页面文件, 申请证书时会在容器中生成 `/container/web/abc.com/.well-known/acme-challenge/xxxxxx` 文件，所以宿主机与容器web目录要映射\n\n```sh\ndocker run --rm -itd \\\n  -v /localhost/out:/acme.sh \\\n  -v /localhost/ssl:/container/ssl \\\n  -v /localhost/web:/container/web \\\n  --net=host \\\n  --name=tacme \\\n  neilpang/acme.sh daemon\n```\n<!-- more -->\n## 测试 acme.sh 是否正常运行\n```sh\ndocker exec tacme acme.sh -v\n#返回如下内容\n#https://github.com/acmesh-official/acme.sh\n#v3.0.8\n```\n\n## 绑定一个邮箱，不然会提示无法生成证书\n> acme.sh 默认是使用 zerossl 颁布证书，需要绑定邮箱。\n\n> 如果切换成使用 letsencrypt 颁布证书就不需要绑定邮箱。\n\n> 绑定邮箱后，申请的证书记录可以在web页面 https://app.zerossl.com/certificates/issued 查看\n```sh\ndocker exec tacme acme.sh --register-account -m abc@qq.com\n```\n\n## 申请ssl证书 \n### 方式1 `--standalone` 模式\n> 如果80端口被占用，在 `--standalone` 模式下要指定另外的端口 `--httpport 81`\n\n> 这里申请的是 顶级域名 `abc.com` 和 二级域名 `www.abc.com` 的多域名证书\n\n> 适用于nginx中配置 `https://abc.com` 顶级域名跳转到 `https://www.abc.com` 二级域名\n```sh\ndocker exec tacme acme.sh --issue \\\n-d abc.com \\\n-d www.abc.com \\\n--standalone \\\n--httpport 81\n```\n\n### 方式2 `-w /container/web/abc.com` 指定容器web页路径\n> 如果出现超时`Timeout`或者`404`找不到`https://www.abc.com/.well-known/acme-challenge/xxxxxx` 文件，很有可能就是`宿主机web根目录没有映射到容器中`, 比如：`/localhost/web:/container/web`\n\n> 需要你指定 `-w /container/web/abc.com` 容器web路径\n```sh\ndocker exec tacme acme.sh --issue \\\n  -d abc.com \\\n  -d www.abc.com \\\n  -w /container/web/abc.com \\\n  --keylength ec-256\n```\n> `--keylength ec-256` #缺省项，指定证书使用的ECC算法，可选值还有 ec-384, ECC 比 RSA 更好。\n\n> 运行成功之后会生成一个以域名开头的文件夹 `/acme.sh/abc.com_ecc` 其中放置着ssl各种证书。\n\n### 方式3 生成泛域名证书\n> 先申请ak，推荐aliyun（最安全的做法是创建ram子用户，给此用户仅添加“管理阿里云解析dns权限”）\nhttps://ak-console.aliyun.com/#/accesskey \nhttps://ram.console.aliyun.com/manage/ak\n\n> 配置环境变量，供后续执行的程序使用\n\n```sh\n#export 可新增，修改或删除环境变量\nexport Ali_Key=\"LTdxxxKvtP\"\nexport Ali_Secret=\"gabUA2xxxxxXT0ehIb9j\"\n```\n> 执行生成通配符域名证书\n```sh\ndocker exec tacme acme.sh --issue \\\n  --dns dns_ali \\\n  -d abc.com \\\n  -d '*.abc.com'\n```\n>证书生成成功之后，Ali_Key/Ali_Secret 会自动保存在 /acme.sh/account.conf 文件中\n\n## 复制和转换证书格式并保存到指定目录\n> `/container/ssl/abc.com/`此目录必须已经存在\n```sh\ndocker exec tacme acme.sh --install-cert \\\n-d abc.com \\\n--key-file       /container/ssl/abc.com/key.pem \\\n--fullchain-file /container/ssl/abc.com/fullchain.pem \\\n--cert-file      /container/ssl/abc.com/cert.pem \\\n--ca-file        /container/ssl/abc.com/ca.pem\n```\n> `-d abc.com`  表示转换 abc.com 域名的证书，会在`/acme.sh/`目录下匹配存放此域名证书的文件夹，比如：abc.com_ecc\n\n## 切换默认证书申请服务器 zerossl 或 letsencrypt\n```sh\ndocker exec tacme acme.sh --set-default-ca --server letsencrypt\ndocker exec tacme acme.sh --set-default-ca --server zerossl\n```\n\n## 在容器中设置定时任务 `crontab -e`\n> `--cron` 运行 cron 作业来更新所有证书\n\n> `--home \"/root/.acme.sh\"`  acme.sh 程序文件所在的目录\n\n> `--config-home \"/acme.sh\"` 存放acme.sh生成的证书及配置文件目录\n\n> `> /dev/null 2>&1` 表示程序执行过程中不打印信息（抛弃正常信息和错误信息）\n```\n0 2 * * * \"/root/.acme.sh\"/acme.sh --cron --home \"/root/.acme.sh\" --config-home \"/acme.sh\" > /dev/null 2>&1\n```\n> 表求在每天的2点，检查证书，如果快过期了，一般是3个月，会在第2个月进行证书更新。\n\n> 执行以下命令行，查看证书下次更新时间\n```\n#在宿主机执行\ndocker exec tacme acme.sh --info -d abc.com\n```\n> 返回如下内容\n```\n[Wed May 29 19:20:40 UTC 2024] The domain 'abc.com' seems to have a ECC cert already, lets use ecc cert.\nDOMAIN_CONF=/acme.sh/abc.com_ecc/abc.com.conf\nLe_Domain='abc.com'\nLe_Alt='www.abc.com'\nLe_Webroot='/container/web/abc.com'\nLe_PreHook=''\nLe_PostHook=''\nLe_RenewHook=''\nLe_API='https://acme-v02.api.letsencrypt.org/directory'\nLe_HTTPPort='88'\nLe_Keylength='ec-256'\nLe_OrderFinalize='https://acme-v02.api.letsencrypt.org/acme/finalize/1635883427/273571115052'\nLe_LinkOrder='https://acme-v02.api.letsencrypt.org/acme/order/1635883427/273571115052'\nLe_LinkCert='https://acme-v02.api.letsencrypt.org/acme/cert/04602e68b39b9fa0f98b4c6f8f7cf41462f0'\nLe_CertCreateTime='1716969431'\nLe_CertCreateTimeStr='2024-05-29T07:57:11Z'\nLe_NextRenewTimeStr='2024-07-27T07:57:11Z'\nLe_NextRenewTime='1722067031'\nLe_RealCertPath='/container/ssl/abc.com/cert.pem'\nLe_RealCACertPath='/container/ssl/abc.com/ca.pem'\nLe_RealKeyPath='/container/ssl/abc.com/key.pem'\nLe_ReloadCmd=''\nLe_RealFullChainPath='/container/ssl/abc.com/fullchain.pem'\n```\n\n## acme.sh 其它命令\n> 详见：https://github.com/acmesh-official/acme.sh\n>查看帮助\n```bash\nacme.sh -h\n```\n>查看所有证书生成列表\n```bash\nacme.sh --list\n```\n>强制重新生成指定证书\n```bash\nacme.sh --renew --force -d abc.com -d www.abc.com\n```\n>强制重新生成所有证书\n```bash\nacme.sh --renew-all --force\n```\n>删除域名更新\n```bash\nacme.sh --remove -d www.abc.com\n```\n>查看域名配置\n```bash\nacme.sh --info -d abc.com\n```","tags":["ssl","https"],"categories":["linux"]},{"title":"Portainer Server 管理本机和远程主机的docker容器","url":"/afd1f77c.html","content":"## 安装 Portainer Server\n\n首先，创建数据卷, 或者在 `docker run` 命令中通过 `-v portainer_data:/data` 创建卷`/var/lib/docker/volumes/portainer_data/_data`\n```bash\ndocker volume create portainer_data\n```\n<!-- more -->\n然后，下载并安装 Portainer Server 容器\n\n{% note info %}\n连接容器时出现 Unable to retrieve image details 错误提示\n因为 portainer-ce 2.19 与 docker-ce 26 不兼容\n解决办法\n1, portainer-ce 2.19 与 docker-ce 25 组合使用. \n2, portainer-ce 2.20 与 docker-ce 26 组合使用.\n{% endnote %}\n\n\n```bash\ndocker run -d \\\n  -p 8000:8000 \\\n  -p 9443:9443 \\\n  --name portainer \\\n  --restart=always \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v portainer_data:/data \\\n  portainer/portainer-ce:2.20.1\n```\n> 默认情况下，Portainer 是通过 `https(9443)` 访问，如果你想使用 `http(9000)` 访问，则加入 `-p 9000:9000`\n\n通过 https://0.0.0.0:9443 访问，第一次需要设置密码。\n\n\n## 安装 Portainer agent\n如果你想管理远程主机上的docker容器，则需要下面的步骤。\n{% note info %}\nportainer-ce 2.20.1 需要与 agent 2.20.1 版本相对应\n{% endnote %}\n一、在 portainer 页面左侧的 `Settings` 中找到 `Environments` 点击进入。\n二、右侧上方 点击 `Add environment` 进入。\n三、选择第一个 `docker standalone`，然后点击下方的 `start wizard`。\n四、选择 `agent` , 选择你的系统 `Linux`, 复制对应的系统代码 `Copy command`，设置 `Name` 为 `docker-prod01`, `Environment address` 为 `远程主机ip:9001`。\n\n最后在远程主机上运行如下命令\n```bash\ndocker run -d \\\n  -p 9001:9001 \\\n  --name portainer_agent \\\n  --restart=always \\\n  -v /var/run/docker.sock:/var/run/docker.sock \\\n  -v /var/lib/docker/volumes:/var/lib/docker/volumes \\\n  portainer/agent:2.20.1\n```\n这样你就会在 portainer 页面的 `Home` 页的右侧看到多出来一个远程的主机，点击进去就可以管理其中的docker 容器了。\n\n## 忘记密码？重新生成 Portainer 登陆密码\n> 运行此命令，下面有步骤详细说明\n```\ndocker stop portainer && \\\ndocker run --rm \\\n-v $(dirname `find /var/lib/docker/volumes -name portainer.key`):/data \\\nportainer/helper-reset-password && \\\ndocker start portainer\n```\n\n>1、先把portainer 容器停止，必须停止\n```sh\ndocker stop portainer\n```\n>2、找到 `portainer.key` 文件所在的目录\n\n```\nfind /var/lib/docker/volumes -name portainer.key\n#返回\n#/var/lib/docker/volumes/portainer_data/_data/portainer.key\n```\n\n>3、执行命令重新生成admin账户密码\n```sh\n#/var/lib/docker/volumes/portainer_data/_data 为portainer.key所在的目录\ndocker run --rm \\\n-v /var/lib/docker/volumes/portainer_data/_data:/data \\\nportainer/helper-reset-password\n```\n\n>返回内容\n```sh\n{\"level\":\"info\",\"filename\":\"portainer.db\",\"time\":\"2024-03-28T06:20:51Z\",\"message\":\"loading PortainerDB\"}\n2024/03/28 06:20:51 Password successfully updated for user: admin\n2024/03/28 06:20:51 Use the following password to login: m8T!yCEG3{+Rtp]el64ZW\n```\n>4、启动容器\n```\ndocker start portainer\n```\n>用户 admin\n密码 m8T!yCEG3{+Rtp]el64ZW\n使用账号和密码登陆portainer，并马上进行后台密码修改。\n","tags":["docker","portainer"],"categories":["linux"]},{"title":"js相同值合并","url":"/17c7b154.html","content":"数组对象相同值相加去重\n<!-- more -->\n\n\n\n\n\n```js\nlet arry=[\n    {Code:'x',Quantity:1,ItemType:1},\n    {Code:'x',Quantity:2,ItemType:2},\n    {Code:'x',Quantity:5,ItemType:3},\n    {Code:'y',Quantity:1,ItemType:4},\n    {Code:'y',Quantity:2,ItemType:5},\n    {Code:'z',Quantity:1,ItemType:6},\n]\n\nfunction SameObjValue(arry){\n    var temp = {};\n    for(var i in arry) {\n        var key= arry[i].Code;\n        if(temp[key]) {\n            temp[key].Code = temp[key].Code;\n            temp[key].Quantity = temp[key].Quantity + arry[i].Quantity;\n            temp[key].ItemType = temp[key].ItemType + arry[i].ItemType;\n\n         } else {\n            temp[key] = {};\n            temp[key].Code = arry[i].Code;\n            temp[key].Quantity = arry[i].Quantity;\n            temp[key].ItemType = arry[i].ItemType;\n        }\n    }\n    let newfood = [];\n    for(var k in temp){\n       newfood.push(temp[k])\n    }\n    return newfood;\n}\n    console.log(SameObjValue(arry));\n/*\n[\n  {Code: \"x\", Quantity: 8, ItemType: 6},\n![upload successful](/images/456.png)\n![upload successful](/images/123.png)\n  {Code: \"y\", Quantity: 3, ItemType: 9},\n  {Code: \"z\", Quantity: 1, ItemType: 6}\n]\n*/\n\n// 更简洁的写法\nvar testArr = [\n        { name: 'aa', num: 10, op: 10 },\n        { name: 'aa', num: 20, op: 20 },\n        { name: 'bb', num: 30, op: 30 },\n        { name: 'cc', num: 10, op: 40 },\n        { name: 'aa', num: 20, op: 50 },\n        { name: 'bb', num: 10, op: 60 },\n        { name: 'dd', num: 10, op: 70 }\n    ];\n/*\n    delSameObjValue 数组对象相同值相加去重\n    arr 需要处理的数组\n    keyName 用于判断相同的键名\n    keyValue 用于计算的键值\n    */\n    function delSameObjValue(arr, keyName, keyValue1, keyValue2) {\n        let baseArr = [], newArr = [];\n        for (let key in arr) {\n            if (baseArr.includes(arr[key][keyName])) {\n                newArr[baseArr.indexOf(arr[key][keyName])][keyValue1] += arr[key][keyValue1];\n                newArr[baseArr.indexOf(arr[key][keyName])][keyValue2] += arr[key][keyValue2];\n            } else {\n                baseArr.push(arr[key][keyName]);\n                newArr.push(arr[key]);\n            }\n        }\n        return newArr;\n    }\n    console.log(delSameObjValue(testArr, 'name', 'num', 'op'));\n/*\n[\n  {name: \"aa\", num: 50, op: 80},\n  {name: \"bb\", num: 40, op: 90},\n  {name: \"cc\", num: 10, op: 40},\n  {name: \"dd\", num: 10, op: 70}\n]\n\n*/\n```","categories":["js"]},{"title":"为Github Gitlab Gitee账户分别设置SSH key","url":"/36a15fb9.html","content":"为Github Gitlab Gitee账户分别设置SSH KEY\n<!-- more -->\n> ## 一、分别生成一对秘钥ssh key\n\n```shell\nssh-keygen -t rsa -C \"github\" -f ~/.ssh/github-rsa\nssh-keygen -t rsa -C \"gitlab\" -f ~/.ssh/gitlab-rsa\nssh-keygen -t rsa -C \"gitee\" -f ~/.ssh/gitee-rsa\n\n配置远程仓库公钥（这里以github为例）：\n#个人头像 -> settings -> SSH and GPG keys -> New SSH key\n## Title    标题 随便写一个\n## Key type 类型 选择 Authentication Key\n## Key      粘贴 github-rsa.pub 公钥内容\n```\n> ## 二、添加私钥到ssh-agent的高速缓存中,提高ssh的认证速度。\n```shell\nssh-add ~/.ssh/github-rsa\nssh-add ~/.ssh/gitlab-rsa \nssh-add ~/.ssh/gitee-rsa\n```\n\n> 默认操作系统是不开启ssh-agent的，需要手动打开\n```shell\n# 开启ssh-agent\nssh-agent bash\n# 查看私钥列表\nssh-add -l\n# 查看公钥列表\nssh-add -L\n# 清空所有密钥\nssh-add -D\n#从ssh-agent中删除某个私钥或者某个公钥\nssh-add -d ~/.ssh/id_rsa\nssh-add -d ~/.ssh/id_rsa.pub\n\n命令选项\n-D 删除ssh-agent中的所有密钥\n-d 从ssh-agent中删除某个密钥\n-e pkcs11：删除PKCS#11共享库pkcs1提供的钥匙\n-s pkcs11：添加PKCS#11共享库pkcs1提供的钥匙\n-L 显示ssh-agent中的公钥\n-l 显示ssh-agent中的私钥\n-t life：对加载的密钥设置超时时间，超时ssh-agent将自动卸载密钥\n-X 对ssh-agent进行解锁\n-x 对ssh-agent进行加锁\n```\n> ## 三、在~/.ssh/下新建一个配置文件 config ，目录结构如下\n```\n/.ssh\n-- config\n-- github-rsa\n-- github-rsa.pub\n-- ...\n```\n> 配置不同仓库对应的ssh key, config 配置文件内容如下\n```sh\n# github\nHost github.com\nHostName github.com\nPreferredAuthentications publickey\nIdentityFile ~/.ssh/github-rsa\n# gitlab\nHost gitlab.com\nHostName gitlab.com\nPreferredAuthentications publickey\nIdentityFile ~/.ssh/gitlab-rsa\n# gitee\nHost gitee.com\nHostName gitee.com\nPreferredAuthentications publickey\nIdentityFile ~/.ssh/gitee-rsa\n\n# Host和HostName填写git服务器的域名，IdentityFile指定私钥的路径\n```\n> ## 测试\n```shell\n# ssh -T git@[config文件中配置的host值]\nssh -T git@github.com\nssh -T git@gitlab.com\nssh -T git@gitee.com\n# 返回如下内容，表示身份验证配置成功\nHi xxxx! You’ve successfully authenticated, but GitHub does not provide shell access.\n```","tags":["git"],"categories":["linux"]},{"title":"git 上传项目到 github","url":"/720a2000.html","content":"> windows 和 debian 安装方法\n<!-- more -->\n<!-- toc -->\n## 一、安装 git\n### windows10\n> 下载地址\n\nhttp://git-scm.com/download/\n> 使用方法\n\n在本地项目目录的空白处右键-\"Open Git Bash here\"\n\n### debian11\n```shell\napt update\napt -y install git\n```\n\n## 二，为Github账户设置SSH key\n```sh\n# 使用ssh-keygen命令生成公钥id_rsa.pub和私钥id_rsa，其中-t表示类型是rsa类型（非对称加密）。\n#直接3次回车,不需要填写\nssh-keygen -t rsa -C \"pub@github\" # -C 表示注释，会出现在公钥内容的末尾（此参数可省略）\n# -C参数省略以后，公钥内容的末尾默认为：用户名@主机名(例如：root@localhost)\n```\n\n#默认生成公钥的位置，\n#C:\\Users\\你的用户名\\.ssh # windows\n#/root/.ssh/             # linux root\n#/home/user/.ssh/   # linux 普通用户\n\n#注意：root和user生成的公钥各自独立，每个用户都要在github后台增加 ssh key\n\n```sh\n# 使用 -f 参数可指定生成的文件名和目录\nssh-keygen -t rsa -f /root/.ssh/id_rsa.github\n# 在/root/.ssh/目录下生成公钥id_rsa.github.pub和私钥id_rsa.github\n```\n\n##################操作说明\n#打开 id_rsa.pub 并复制公钥内容，在 github.com 用户后台页面左侧新增一个 ssh key\n#个人头像 -> settings -> SSH and GPG keys -> New SSH key\n##Title    标题 随便写一个\n##Key type 类型 选择 Authentication Key\n##Key      粘贴 id_rsa.github.pub 公钥内容\n\n#id_rsa.github.pub 公钥内容类似如下：\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAA3U= pub@github\n\n## 三、全局部署 GitHub 用户名和邮箱，让 GitHub 知道你是谁。\n> 用户名：abc123 邮箱：abc123@gmail.com\n```shell\ngit config --global user.email abc123@gmail.com\ngit config --global user.name abc123\n#可选(有时会提示增加一个安全目录)\ngit config --global --add safe.directory /home/hexo/.hexo\n```\n## 四，上传本地项目\n### 1、第一次上传新项目\n> 适用于：本地项目第一次上传。在\"project\"下执行 git 命令，目录结构如下：\n```\n/project\n-- 项目文件1\n-- 项目目录1\n---- 项目文件2\n```\n```shell\n# 初始化本地项目，会在本地项目目录下新建 .git 文件夹（此文件夹是隐藏的）\ngit init\n\n# 设置别称 node_test 并与远程仓库关联，别称可以随便起（仅第一次需要）\ngit remote add node_test git@github.com:abc123/node_demo.git\n\n# 把准备添加到仓库的文件放到暂存区\ngit add .       #添加project目录内所有文件\ngit add 项目目录1/ #添加project目录下的项目目录1内所有文件\ngit add README.md  #添加project目录中单个文件\n\n# 准备提交到仓库 -m \"此处是目录或文件的更新日志\"\ngit commit -m \"修改了文件中的小bug\"\n\n# 第一次上传项目时，为项目设置一个分支，不设置则默认是 master，这里定义的是 main 分支（此步为可选）\n#git branch -M main\n\n# 如果你是修改代码后上传到仓库，这一步是标准操作，也是个好习惯（如果是新创建的仓库，可以省略）\n# 拉取仓库数据， -r 指定pull的方式为rebase。文章底部有关于 pull 方式的解释\ngit pull -r node_test master   # master 是仓库的分支\n\n# 上传代码到GitHub仓库\ngit push -u node_test master # master 是仓库的分支\n```\n### 2、为远程项目新增内容\n> 适用于：本地项目已经被删除时，想把\"新建文件夹\"下的内容上传到github仓库中。在\"新建文件夹\"下执行 git 命令，目录结构如下：\n```\n/新建文件夹\n-- 要新增的文件1\n-- 要新增的目录1\n---- 要新增的文件2\n```\n\n```shell\n# 先初始化\ngit init\n\n# 为仓库 git@github.com:abc123/node_demo.git 创建别名 node_test 方便后面简化操作\ngit remote add node_test git@github.com:abc123/node_demo.git\n\n# 拉取仓库数据， -r 指定pull的方式为rebase\n# 文章底部有关于 pull 方式的解释\ngit pull -r node_test master\n\n#添加目录内所有文件到暂存区\ngit add .\n\n#提交并为每个文件加上日志说明\"add posts\"\ngit commit -m \"add posts\"\n\n#上传\ngit push -u node_test master\n```\n\n## 总结\n> 每次修改本地项目后都要进行上面的操作太麻烦了，如果不是第一次上传，可以简化命令，最多只需要4步\n```shell\n# 1、添加目录内所有文件操作到暂存区（文件操作包括：修改、删除、新增文件）\ngit add .\n\n# 2、提交文件操作并加上日志\"ssl bugs xxx\"\ngit commit -m \"ssl bugs xxx\"\n\n# 如果文件操作只是修改、删除文件，没有新增文件，第1步和第2步可以合并成一条命令，如下：\ngit commit -a -m \"ssl bugs xxx\" 或 git commit -am \"ssl bugs xxx\"\n#以下是返回内容\n#[master df65159] ssl bugs xxx\n#2 file changed, 2 insertion(+), 2 deletion(-)\n\n# 3、从远程仓库拉代码（当仓库有多个管理者时，此为标准动作）\ngit pull\n#以下是返回内容\n#Current branch master is up to date.\n\n# 4、上传\ngit push\n#以下是返回内容\n#Enumerating objects: 16, done.\n#Counting objects: 100% (16/16), done.\n#Delta compression using up to 2 threads\n#Compressing objects: 100% (9/9), done.\n#Writing objects: 100% (9/9), 1.43 KiB | 730.00 KiB/s, done.\n#Total 9 (delta 5), reused 0 (delta 0), pack-reused 0\n#remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\n#To github.com:abc123/hexo_project.git\n#   f6b5b58..9d2c11f  master -> master\n\n```\n## pull 方式的区别\n\n> merge 是一个合并操作，将两个分支的修改合并在一起，会提交合并中修改的内容。\n\n> rebase 并没有进行合并操作，只是提取了当前分支的修改。rebase 操作会丢弃当前分支已提交的 commit，不要在有协作开发的分支上执行 rebase 操作。\n\n```shell\n# 在每次执行 git pull 命令之前运行一次\ngit config pull.rebase false  # merge\n#或者\ngit config pull.rebase true   # rebase\n# 然后再执行 git pull 命令\ngit pull node_test master\n\n# 以上也可以直接合并成一条命令\ngit pull -r node_test master\n# 或者\ngit pull --rebase node_test master\n\n# 当然，你还可以通过执行 git config --global 命令来永久指定默认的处理方式，比如：\ngit config --global pull.rebase true  # 设置默认使用 rebase 方式\n# 以后直接\ngit pull node_test master\n\n```\n## 上传时排除文件和目录\n如果只想上传一部分文件可以在项目目录下创建一个名为 .gitignore 的文件，在里面加上不想上传的文件或目录即可，例如：\n```\n.DS_Store\nThumbs.db\ndb.json\n*.log\nnode_modules/\npublic/\n.deploy*/\n_multiconfig.yml\nthemes/\n.git/\n.github/\ndesktop.ini\n```\n## git 其他命令\n```shell\n#查看本地修改项\ngit status\n\n```","tags":["git"],"categories":["linux"]},{"title":"docker镜像瘦身工具slim","url":"/5c8569fd.html","content":"## 安装\n> 注意：通过 https://github.com/slimtoolkit/slim 下载的是源代码，需要编译。\n```shell\nwget https://downloads.dockerslim.com/releases/1.40.3/dist_linux.tar.gz && \\\ntar zxf dist_linux.tar.gz && \\\nmv dist_linux/* /usr/local/bin/ && \\\ndocker-slim --version\n```\n<!-- more -->\n## 使用\n> 把镜像 archlinux:latest 瘦身后更名为 archlinux:curl\n```shell\n#下载镜像\ndocker pull archlinux:latest\n# 镜像瘦身\nslim build \\\n--target archlinux:latest \\\n--tag archlinux:curl \\\n--http-probe=false\n```\n## 文档\n```shell\n#查看帮助，或者详见github官网文档。\nslim build --help\n```","tags":["slim"],"categories":["docker"]},{"title":"node环境搭建及pm2应用管理","url":"/f34d6799.html","content":"node 环境配置 使用 docker node:alpine 镜像\n> node 演示 https://github.com/wenyamu/node_demo\n<!-- more -->\n<!-- toc -->\n\n### 创建node环境\n```yml\nversion: '3'\nservices:\n  dc1:\n    # 镜像本地无则自动下载\n    image: node:alpine\n    hostname: nodeHost\n    # 映射端口 【宿主机端口:容器端口】\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    # 目录挂载 【宿主机目录:容器目录】\n    volumes:\n      - /root/node:/node\n\n    # 容器名称\n    container_name: nodetest\n    #environment:\n    #  - \"SERSYNC=true\"\n    restart: always\n    # 相当于 docker run -i\n    stdin_open: true\n    # 相当于 docker run -t\n    tty: true\n\n```\n\n### 新建项目目录并初始化\n```shell\nmkdir -p /node\ncd /node\nnode init -y\n```\n### 项目目录结构\n```\n/\n-- node\n---- test.config.js\n---- test.json\n---- www\n------ server.js\n------ view\n-------- index.html\n\n```\n\n### 安装应用的依赖包\n```shell\ncd /node\nnpm install http koa\n```\n\n#### 全部的依赖包\n```js\n\"dependencies\": {\n    \"fs\": \"^0.0.1-security\",\n    \"http\": \"^0.0.1-security\",\n    \"https\": \"^1.0.0\",\n    \"ioredis\": \"^5.3.2\",\n    \"koa\": \"^2.14.2\",\n    \"koa-nunjucks-2\": \"^3.0.2\",\n    \"koa-router\": \"^12.0.0\",\n    \"koa-sslify\": \"^5.0.1\",\n    \"koa-static\": \"^5.0.0\",\n    \"mongodb\": \"^5.7.0\",\n    \"mysql\": \"^2.18.1\",\n    \"path\": \"^0.12.7\",\n    \"pm2\": \"^5.3.0\",\n    \"redis\": \"^4.6.7\",\n    \"url\": \"^0.11.1\"\n  }\n```\n> 当然，如果你有 package.json 文件，可以拷贝到项目根目录，然后使用如下命令安装：\n```shell\ncd /node\nnpm install\n```\n\n> 新建 /node/www/server.js\n```js\nconst Koa = require('koa');\nconst router = require('koa-router')();\n// 引入 koa-nunjucks-2（nunjucks模板中间件）\nconst koaNunjucks = require('koa-nunjucks-2');\nconst path = require('path');\nconst static = require('koa-static');//引用静态\nvar app = new Koa();\n// 使用中间件，利用path模块的方法拼接出静态文件目录的绝对路径\napp.use(static(path.join(__dirname,\"public\"),{ extensions: ['html']}));\n/* 使用 koa-nunjucks-2 实例获得中间件*/\napp.use(koaNunjucks({\n    ext: 'html', // 使用HTML后缀的模板\n    //path: path.join(__dirname, 'view'), // 模板所在路径\n    path: __dirname + \"/view\", // 模板所在路径，同上\n    nunjucksConfig: { // nunjucks的配置\n        trimBlocks: true\n    }\n}));\n\nrouter.get('/', async (ctx) => {\n    await ctx.render('index', {title:'Hello Node!', info:'node'});\n});\n\n// 添加路由中间件\napp.use(router.routes());\napp.use(router.allowedMethods());\napp.listen(80)\nconsole.log('正在监听80端口，请使用 ip:80 访问');\n\n```\n> 新建 /node/www/view/index.html\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>{{ title }}</title>\n</head>\n<body>\n    <h1>欢迎来到 {{info}} ，我是一个模板文件</h1>\n\n</body>\n</html>\n\n```\n> 启动应用\n\n```shell\n# 进入项目根目录\ncd /node\n\n# 启动 node 应用\nnode www/server.js\n```\n\n> 使用 ip:80 访问 得到如下结果\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Hello Node!</title>\n</head>\n<body>\n    <h1>欢迎来到 node ，我是一个模板文件</h1>\n\n</body>\n</html>\n```\n\n### 使用pm2管理node应用\n```shell\n# 全局安装（推荐全局安装）\nnpm install pm2@latest -g\n```\n#### pm2常用命令\n```shell\n# 先进入node项目目录\ncd /node\n\n# 启动应用程序\npm2 start www/server.js\n\n# 您还可以启动其他类型的应用程序，如 bash 命令、python\npm2 start \"npm run start\"\npm2 start app.py\n\n# 重新启动应用程序\npm2 restart [id|name]\n\n# 停止指定的应用程序\npm2 stop [id|name]\n\n# 删除应用程序\npm2 delete [id|name]\npm2 del [id|name]\npm2 del all # 删除所有应用程序\n\n# 列出所有正在运行的应用程序：\npm2 list\n\n# 监控面板，通过终端轻松直接地监控内存和CPU\npm2 monit\n\n# 查看应用程序数据\npm2 show [id|name]\n\n```\n#### pm2多应用管理\n> 1、使用 .config.js 格式配置文件\n\n> 当同时管理多个应用程序或必须指定多个选项时，您可以使用配置文件。\n> /node/test.config.js 文件的示例：\n```js\n// 注意：文件必须以 .config.js 后缀结尾，不然无法启动\nmodule.exports = {\n  apps : [{\n    name   : \"limit worker\",\n    script : \"./www/worker.js\",\n    args   : \"limit\"\n  },{\n    name   : \"rotate worker\",\n    script : \"./www/worker.js\",\n    args   : \"rotate\"\n  }]\n}\n```\n```shell\n# 启动\ncd /node\npm2 start test.config.js\n```\n\n> 2、使用 .json 格式配置文件\n\n> /node/test.json 文件的示例：\n```js\n{\n  \"apps\": [\n    // 应用1\n    {\n      \"name\": \"server1\",// 应用名称\n      \"script\": \"./www/server.js\",// 应用相对于 node 根目录的路径\n      \"log_date_format\": \"YYYY-MM-DD HH:mm:ss\",\n      \"error_file\": \"logs/node-server1.stderr.log\",\n      \"out_file\": \"logs/node-server1.stdout.log\",\n      \"pid_file\": \"pids/node-server1.pid\",\n      \"instances\": 1,// 启动实例数\n      \"min_uptime\": \"120s\",\n      \"max_restarts\": 10,\n      \"max_memory_restart\": \"100M\",\n      \"cron_restart\": \"1 0 * * *\",\n      \"watch\": false,// 热加载\n      \"merge_logs\": true,\n      \"exec_interpreter\": \"node\",\n      \"exec_mode\": \"fork\",// cluster 或 fork, 默认 fork\n      \"autorestart\": true,\n      \"vizion\": false\n    },\n    //应用2\n    {\n      \"name\": \"server2\",// 应用名称\n      \"script\": \"./www/my.js\",// 应用相对于 node 根目录的路径\n      \"log_date_format\": \"YYYY-MM-DD HH:mm:ss\",\n      \"error_file\": \"logs/node-server2.stderr.log\",\n      \"out_file\": \"logs/node-server2.stdout.log\",\n      \"pid_file\": \"pids/node-server2.pid\",\n      \"instances\": 2,// 启动实例数\n      \"min_uptime\": \"120s\",\n      \"max_restarts\": 10,\n      \"max_memory_restart\": \"100M\",\n      \"cron_restart\": \"1 0 * * *\",\n      \"watch\": false,// 热加载\n      \"merge_logs\": true,\n      \"exec_interpreter\": \"node\",\n      \"exec_mode\": \"cluster\",// cluster 或 fork, 默认 fork\n      \"autorestart\": true,\n      \"vizion\": false\n    }\n  ]\n}\n```\n```shell\n# 启动\ncd /node\npm2 start test.json\n```","tags":["pm2"],"categories":["node"]},{"title":"docker常用命令","url":"/749ad7d8.html","content":"> 使用docker \n> docker 介绍\n> docker 容器搭建\n<!-- more -->\n<!-- toc -->\n### docker 基础命令\n\n```shell\n# 重启 docker 服务\nsystemctl restart docker\n\n# 开启 docker 服务\nsystemctl start docker\n\n# 查看 docker 服务状态\nsystemctl status docker\n\n# 搜索镜像\ndocker search nginx\n\n# 拉取镜像\ndocker pull nginx:1.24.0\n\n# 查看本机存在的镜像\ndocker images\n\n# 查看本机存在的容器\ndocker ps -a\n\n# 查看本机正在运行的容器\ndocker ps\n```\n\n### docker 容器命令\n```shell\ndocker run -itd \\\n  -p 80:80 \\\n  -p 443:443 \\\n  -e USERNAME=aaa \\\n  -e PASSWORD=bbb \\\n  -v /mnt/ftp:/home/vsftpd \\\n  --name=nginxweb \\\n  --restart=always \\\n  nginx:1.24.0\n\n# run 创建容器后直接运行\n# -it 表示交互, -d 表示后台运行。简写就是 -itd\n# -p  表示端口映射，前面是宿主机端口，后面是容器端口\n# -e  设置容器的变量名和值\n# -v  表示目录映射，前面是宿主机目录，后面是容器目录\n# --name=nginxweb 定义创建容器的名称为 nginxweb\n# --restart=always 表示容器自动重启\n# nginx:1.24.0 表示创建容器使用的镜像和镜像版本\n\n# 进入容器\ndocker exec -it nginxweb bash\n\n# 停止容器\ndocker stop nginxweb\n\n# 启动容器\ndocker start nginxweb\n\n# 重启容器\ndocker restart nginxweb\n\n# 查看容器的ip地址\ndocker inspect nginxweb | grep '\"IPAddress\"'\ndocker inspect --format '{{ .NetworkSettings.Networks.bridge.IPAddress }}' nginxweb\n\n# 删除容器 需要先停止容器\ndocker stop nginxweb && docker rm nginxweb\n\n# 删除镜像 需要先删除使用此镜像的所有容器\ndocker stop nginxweb && docker rm nginxweb && docker rmi nginx:1.24.0\n\n```\n\n### docker 网络操作命令\n```shell\ndocker network ls\ndocker network inspect mynet\ndocker network inspect mynet | grep '\"Subnet\"'\ndocker network inspect mynet | grep '\"Gateway\"'\ndocker network rm mynet\n\n#不在同一网段内的容器，ping不通\n#把容器 nginxtest 加入到 mynet 中，这时此容器有两个ip\ndocker network connect mynet nginxtest\n\n```\n\n### 通过 dockerfile 文件创建镜像\n> 先进入 dockerfile 文件所在目录下执行命令\n```shell\n# 注意最后有一个.号\ndocker build -t nginxdiy:v1.0 .\n# nginxdiy:v1.0 表示创建的镜像名称和版本号\n```\n\n### 使用 docker compose 创建容器\n> 把所有docker命令写在compose.yml格式文件中，使用docker compose执行创建容器\n```shell\ndocker compose -f compose.yml up -d\n# -f 指定文件路径\n# -d 表示后台运行\n```\n#### compose.yml 格式\n```yml\nversion: '3'\nnetworks:\n  mynet:\n  ipam:\n    config:\n    - subnet: 172.20.0.0/16\nservices:\n  dc1: # 作为转发服务器 80端口\n    # 依赖于nginx镜像（nginx/1.24.0），本地无则自动下载\n    image: nginx:1.24.0\n    hostname: nginxHost_s1\n    # 映射端口 【宿主机端口:容器端口】\n    ports:\n      - \"81:80\"\n      - \"444:443\"\n    # 目录挂载 【宿主机目录:容器目录】\n    volumes:\n      - /www1/web:/usr/share/nginx/html\n      - /www1/conf_s:/etc/nginx/conf.d\n      - /www1/logs:/var/log/nginx\n      - /www1/ssl:/ssl\n    # 容器名称\n    container_name: nginx_s1\n    #environment:\n    #  - \"SERSYNC=true\"\n    restart: always\n    # 相当于 docker run -i\n    stdin_open: true\n    # 相当于 docker run -t\n    tty: true\n    # 指定容器的ip\n    #networks:\n    #  mynet:\n    #    ipv4_address: 172.20.0.3\n    # 容器的ip在设置的网络名的网段中随机生成\n    networks:\n      - mynet\n\n```\n### 为容器追加参数\n```shell\n# 为容器 nginxtest 加上重启参数 --restart=always\ndocker update --restart=always nginxtest\n# 查看更多帮助\ndocker update --help\n```","categories":["docker"]},{"title":"docker-ce安装","url":"/ea332afd.html","content":"> docker 安装程序\n> 自动判断 centos / debian / ubuntu 系统安装 docker\n<!-- more -->\n```sh\n#!/bin/bash\n\n#使用方法\n#wget -N --no-check-certificate https://www.xxx.com/test/docker-ce.sh\n#chmod +x ./docker-ce.sh && ./docker-ce.sh\n\necho \"#############################\"\necho \"### 安装 docker-ce        ###\"\necho \"### CentOS 7              ###\"\necho \"### CentOS Stream 8       ###\"\necho \"### CentOS Stream 9       ###\"\necho \"### Debian 12 (Bookworm)  ###\"\necho \"### Debian 11 (Bullseye)  ###\"\necho \"### Ubuntu 23.10 (Mantic) ###\"\necho \"### Ubuntu 22.04 (Jammy)  ###\"\necho \"### Ubuntu 20.04 (Focal)  ###\"\necho \"#############################\"\n\n# 注意：定义的函数名不能含有字符\"-\"\n### 一，在 centos 上安装 docker-ce\n#https://docs.docker.com/engine/install/centos/\nfunction install_docker_ce_centos() {\n    echo \"卸载旧版本\"\n    sudo yum remove -y docker \\\n             docker-client \\\n             docker-client-latest \\\n             docker-common \\\n             docker-latest \\\n             docker-latest-logrotate \\\n             docker-logrotate \\\n             docker-engine \\\n             docker-selinux\n\n    echo \"安装需要的软件包\"\n    # 安装需要的软件包,yum-util 提供 yum-config-manager 功能，另外两个是 device mapper 驱动依赖的\n    sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n\n    echo \"设置yum源\"\n    sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n\n    #echo \"查看docker版本列表\"\n    # 可以查看所有仓库中所有docker版本\n    #yum list docker-ce --showduplicates | sort -r\n    # 安装上面查询到的指定docker版本\n    #VERSION_STRING=\"23.0.6\"\n    #sudo yum install -y docker-ce-${VERSION_STRING} docker-ce-cli-${VERSION_STRING} containerd.io docker-buildx-plugin docker-compose-plugin\n\n    echo \"安装docker ...\"\n    # 安装 docker 到最新版\n    sudo yum install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n    echo \"启动docker-ce服务并将其加入开机自启\"\n    # 启动\n    sudo systemctl start docker\n\n    # 加入开机自启\n    sudo systemctl enable docker\n\n    echo \"查看 docker-ce 版本 ...\"\n    docker version\n}\n\n### 二，在 debian 上安装 docker-ce\n#https://docs.docker.com/engine/install/debian/\nfunction install_docker_ce_debian() {\n    echo \"卸载以避免与 Docker Engine 版本冲突 ...\"\n    for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done\n    \n    #设置存储库\n    echo \"更新apt包索引并安装包以允许apt通过 HTTPS 使用存储库\"\n    sudo apt-get -y update\n    sudo apt-get -y install ca-certificates curl\n    \n    echo \"添加Docker官方GPG密钥\"\n    sudo install -m 0755 -d /etc/apt/keyrings\n    curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc\n    sudo chmod a+r /etc/apt/keyrings/docker.asc\n    \n    echo \"将存储库添加到 Apt 源\"\n    echo \\\n    \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \\\n    \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n    tee /etc/apt/sources.list.d/docker.list > /dev/null\n    \n    #安装 Docker 引擎\n    echo \"更新apt包索引\"\n    sudo apt-get -y update\n    \n    #echo \"查看docker版本列表\"\n    # 可以查看所有仓库中所有docker版本\n    #apt list -a docker-ce\n    # 安装上面查询到的指定docker版本\n    #VERSION_STRING=\"5:25.0.5-1~debian.11~bullseye\"\n    #sudo apt-get install -y docker-ce=${VERSION_STRING} docker-ce-cli=${VERSION_STRING} containerd.io docker-buildx-plugin docker-compose-plugin\n\n    echo \"安装 Docker 引擎、containerd 和 Docker Compose 最新版\"\n    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n    \n    echo \"查看 docker-ce 版本 ...\"\n    docker version\n\n}\n\n### 三，在 ubuntu 上安装 docker-ce\n#https://docs.docker.com/engine/install/ubuntu/\nfunction install_docker_ce_ubuntu() {\n    echo \"卸载以避免与 Docker Engine 版本冲突 ...\"\n    for pkg in docker.io docker-doc docker-compose docker-compose-v2 podman-docker containerd runc; do sudo apt-get remove $pkg; done\n    \n    #设置存储库\n    echo \"更新apt包索引并安装包以允许apt通过 HTTPS 使用存储库\"\n    sudo apt-get -y update\n    sudo apt-get -y install ca-certificates curl\n    \n    echo \"添加Docker官方GPG密钥\"\n    sudo install -m 0755 -d /etc/apt/keyrings\n    curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n    sudo chmod a+r /etc/apt/keyrings/docker.asc\n    \n    echo \"将存储库添加到 Apt 源\"\n    echo \\\n    \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n    \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n    tee /etc/apt/sources.list.d/docker.list > /dev/null\n    \n    #安装 Docker 引擎\n    echo \"更新apt包索引\"\n    sudo apt-get -y update\n    echo \"安装 Docker 引擎、containerd 和 Docker Compose 最新版\"\n    sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n\n    echo \"查看 docker-ce 版本 ...\"\n    docker version\n\n}\n\necho \"确认系统版本并安装对应 docker\"\ncheck_sys(){\n    #如果存在 /etc/redhat-release 文件，则为 centos\n\tif [[ -f /etc/redhat-release ]]; then\n        install_docker_ce_centos\n\telif cat /etc/issue | grep -q -E -i \"debian\"; then\n        install_docker_ce_debian\n\telif cat /etc/issue | grep -q -E -i \"ubuntu\"; then\n        install_docker_ce_ubuntu\n\telif cat /etc/issue | grep -q -E -i \"centos|red hat|redhat\"; then\n        install_docker_ce_centos\n\t#elif cat /proc/version | grep -q -E -i \"debian\"; then\n    #    install_docker_ce_debian\n\t#elif cat /proc/version | grep -q -E -i \"ubuntu\"; then\n    #    install_docker_ce_ubuntu\n\t#elif cat /proc/version | grep -q -E -i \"centos|red hat|redhat\"; then\n    #    install_docker_ce_centos\n    fi\n}\n\ncheck_sys\n\n```","categories":["docker"]},{"title":"安装pypy3为python3提速","url":"/652f3f3a.html","content":"据说让 python3 提速10倍 | debian 安装 pypy3\n\n<!-- more -->\n## 安装pypy3\n> pypy3 对应的是 python3\n```shell\napt update\napt install -y pypy3\n```\n## 安装pip3\n```shell\nwget https://bootstrap.pypa.io/get-pip.py\npython3 get-pip.py\n# 或者\napt install -y pip-python3\n```\n## 升级pip\n```shell\npip3 install --upgrade pip\n# 或者\npython3 -m pip install --upgrade pip\n```\n\n## 安装模块\n```shell\npip3 install termcolor\n# 或者\npython3 -m pip install termcolor\n\n# 如果 pypy3 运行时无法调用模块，可以试试\npypy3 -m pip install termcolor\n```\n## 测试代码 test1.py\n```py\n# pypy3 与 python3 的速度对比\nimport time\n#from termcolor import colored\n\nstart = time.time()\nnumber = 0\nfor i in range(100000000):\n    number += i\n\n#print(colored(\"FINISHED\", \"green\"))\nprint(f'Ellapsed time: {time.time() - start} s')\n```\n### test1.py 测试结果\n```shell\nroot@sg:~# pypy3 test1.py\nFINISHED\nEllapsed time: 0.23811650276184082 s\nroot@sg:~# python3 test1.py\nFINISHED\nEllapsed time: 11.29741096496582 s\n```\n## 测试代码 test2.py\n```py\n# pypy3 与 python3 的速度对比\nimport time\n\nstart_time=time.time()\ntotal=0\nfor i in range(1,5000):\n    for j in range(1,5000):\n        total+=i*j-2*j-2*i\n\nprint(f\"计算结果:{total}\")\nend_time=time.time()\nprint(f\"耗时{end_time-start_time:.2f}秒\")\n```\n### test2.py 测试结果\n```shell\nroot@sg:~# pypy3 test2.py\n计算结果:155937606240000\n耗时0.08秒\nroot@sg:~# python3 test2.py\n计算结果:155937606240000\n耗时5.59秒\n```\n\n> pypy3 比 python3 快了好多\n\n## Python 虚拟环境\n> Python 应用经常需要使用一些包第三方包或者模块，有时需要依赖特定的包或者库的版本，所以不能有一个能适应所有 Python 应用的软件环境，很多时候不同的 Python 应用所依赖的版本是冲突的，满足了其中一个，另一个则无法运行，解决这一问题的方法是 虚拟环境。虚拟环境是一个包含了特定 Python 解析器以及一些软件包的自包含目录，不同的应用程序可以使用不同的虚拟环境，从而解决了依赖冲突问题，而且虚拟环境中只需要安装应用相关的包或者模块，可以给部署提供便利。\n\n```shell\n# 有时会提示安装 ensurepip (Debian/Ubuntu)\napt install python3-venv\n\n# 在当前目录创建一个名为 diy-env 的虚拟环境\npython3 -m venv diy-env\n#root@localhost:~/python/test# python3 -m venv diy-env\n\n# 激活 diy-env 虚拟环境（会在命令行最前面出现当前激活的虚拟环境标记）\nsource diy-env/bin/activate\n#root@localhost:~/python/test# source diy-env/bin/activate\n#(diy-env) root@localhost:~/python/test#\n\n# 退出虚拟环境\ndeactivate\n#(diy-env) root@localhost:~/python/test# deactivate\n#root@localhost:~/python/test#\n```","categories":["python"]},{"title":"linux基础命令","url":"/503970b4.html","content":"linux 命令收集\n\n<!-- more -->\n## 系统命令\n> 通用\n```shell\n#echo \"内核版本\"\nuname -r\n\n#echo \"系统类型\"\nuname -s\n\n```\n> debian\n```shell\n#echo \"linux版本\"\ncat /etc/os-release\n\n#echo \"更新系统安装源\"\napt update\napt -y install 软件包名\n\n```\n> alpine\n```shell\n#echo \"linux版本\"\ncat /etc/alpine-release\n\n#echo \"更新系统安装源\"\napk update\n\n# 相当于 先更新、再安装、最后删除缓存\napk add --update --no-cache 软件包名\n\n```\n> centos\n```shell\n#echo \"linux版本\"\ncat /etc/redhat-release \n\n#echo \"更新系统安装源\"\nyum update\nyum -y install 软件包名\n\n```\n## 日期时间\n> 年月日\n```shell\necho $(date +%F)\t# 2023-08-20\necho $(date +%Y/%m/%d)\t# 2023/08/20 ; %Y: 年 | %m: 月 | %d: 日\n```\n> 时分\n```shell\necho $(date +%R)\t# 18:17\n```\n> 时分秒\n```shell\necho $(date +%T)\t# 18:17:21\necho $(date +%H:%M:%S)\t# 18:17:21 ; %H: 时 | %M: 分 | %S: 秒\n```\n> 星期\n```shell\necho $(date +%A)\t# Sunday | 中文环境输出星期日\n```\n>年月日时分秒\n```shell\necho $(date +%F%n%T)\t\t\t# 2023-08-20 18:18:21\necho $(date +%Y/%m/%d%n%H:%M:%S)\t# 2023/08/20 18:18:21 ; %n: 空格\n```\n\n> 下载文件\n```shell\nwget -N --no-check-certificate https://www.xxx.com/test/install.sh\n\n# 给.sh文件设置755权限\n#chmod +x ./install.sh\n\n# 执行\n./install.sh\n```\n\n> 输入数字安装对应软件的原理示例\n```sh\n#!/bin/bash\n\necho \"##############################\"\necho \"### 1: 查看 docker-ce 版本 ###\"\necho \"### 2: 查看 docker 版本    ###\"\necho \"### 3: 查看 linux 内核版本 ###\"\necho \"##############################\"\n\n# 注意：定义的函数名不能含有字符\"-\"\n### 一，查看 docker-ce 版本\nfunction show_docker_ce() {\n    echo \"docker-ce 版本\"\n    docker version\n}\n\n### 二，查看 docker 版本\nfunction show_docker() {\n    echo \"docker 版本\"\n    docker --version\n}\n\n### 三，查看 linux 内核版本\nfunction show_linux() {\n    echo \"linux 内核版本\"\n    uname -r\n}\n\n# 注意：定义变量时，=号前后不能有空格\nread -p \"请输入对应编号或编号组合 : \" SOFT_NUM\n#如果 ${SOFT_NUM} 字符串为空，则默认为0\nif [ -z \"${SOFT_NUM}\" ];then\n\tSOFT_NUM=0\nfi\n\n#过滤输入的字符（具体命令释义见文末）\n#1，提取其中的数字1-3，因为软件就三个，1-3对应三个软件\n#2，为每个数字前加上空格，为第三步做准备\n#3，替换空格为换行，为第四步做好准备\n#4，按从小到大进行排序，并删除重复数字，只保留一个\n#5，再把换行替换成空格，为第六步做好准备\n#6，去掉字符串中的所有空格\n#最后得到的软件编号和组合编号就只有7种形式：1,2,3,12,23,13,123\n\nfilter_num=`echo ${SOFT_NUM} | tr -cd \"[1-3]\" | sed 's/./& /g' | tr ' ' '\\n' | sort -nu | tr '\\n' ' ' | sed s/[[:space:]]//g`\n\n#此case必须放置在定义的函数后面，不然会提示找不到函数，无法执行\ncase $filter_num in\n 1)\n    show_docker_ce\n ;;\n 2)\n    show_docker\n ;;\n 3)\n    show_linux\n ;;\n 12)\n    show_docker_ce\n    show_docker\n ;;\n 13)\n    show_docker_ce\n    show_linux\n ;;\n 23)\n    show_docker\n    show_linux\n ;;\n 123)\n    show_docker_ce\n    show_docker\n    show_linux\n ;;\n *)\n    echo \"请重新输入编号或编号组合\"\n ;;\nesac\n```\n\n> 以上代码中对字符串的操作详解\n```shell\nnum=\"1, 3 2 1-01  - 2345 231 4224533115\"\necho ${num} | tr -cd \"[0-9]\" | sed 's/./& /g' | tr ' ' '\\n' | sort -nu | tr '\\n' ' ' | sed s/[[:space:]]//g\n\n#释义tr -cd \"[0-9]\"\n\n#tr 是translate的缩写，主要用于删除文件中的控制字符，或者进行字符转换\n#-d 表示删除\n#[0-9] 表示所有数字\n#-c 表示对条件取反\n#tr -cd \"[0-9]\" 的意思：剔除非数字的字符\n\n#释义tr ' ' '\\n' | sort -nu\n\n#tr ' ' '\\n' 把空格替换成换行\n#sort -n 表示把字符串按数字进行从小到大排序 #sort -u 去除重复数字，只保留一个\n# 注意：此两个命令结合才能起到排序的作用（因为sort默认是处理文件的，加上换行欺骗它这是文件）\n\n#释义sed命令\n\nstr='bbc123uu789'\necho $str\n#bbc123uu789\n\n#在每个字符后加上+号\necho $str|sed 's/./&\\+/g'\n#b+b+c+1+2+3+u+u+7+8+9+\n\n#在每个字符后加上空格\necho $str|sed 's/./& /g'\n#b b c 1 2 3 u u 7 8 9 \n\n#以固定长度用空格分隔（三个.表示每三个字符分隔一次）\necho $str|sed 's/.../& /g'\n#bbc 123 uu7 89\n\n#去除字符串中的所有空格\nstr2='b b c 1 2 3 u u 7 8 9'\necho $str2|sed s/[[:space:]]//g\n#bbc123uu789\n```\n\n## ~/的意义\n#~/是进入当前用户的主目录。\n#比如我用的用户名是 user123 那么命令 cd ~/ 就进入了/home/user123 目录。\n#如果使用 root 用户,那么命令 cd ~/ 就进入了/root\n\n\n## 为 ~/.acme.sh/acme.sh 设置别名\n#好像需要重启，acme.sh xxxx 才能生效。如何让别名立即生效呢？\n编辑相对应的`~/.bashrc`文件\n添加 `alias acme.sh='~/.acme.sh/acme.sh'`\n\n或者执行命令\n`echo \"alias acme.sh='~/.acme.sh/acme.sh'\" >> ~/.bashrc`\n\n保存后运行 `source ~/.bashrc` 使别名立即生效\n\n","categories":["linux"]},{"title":"vsftpd的搭建和使用-虚拟多用户配置","url":"/ff5f9e62.html","content":"<!-- toc -->\nvsftpd的搭建和使用-虚拟多用户配置\n\n> 服务器环境\ncentos 7.6\n<!--more-->\n## 安装ftp服务\n\n### 安装 vsftpd\n```shell\nyum install -y vsftpd\n```\n### 安装虚拟用户数据库\n后面用到的 db_load 命令\n```shell\nyum -y install libdb-utils\n```\n### 启动FTP服务\n```shell\nsystemctl start vsftpd.service\n```\n### 设置FTP服务开机自启动\n```shell\nsystemctl enable vsftpd.service\n```\n其它相关命令\n```shell\nsystemctl restart vsftpd.service # 重启服务\nsystemctl status vsftpd.service  # 服务状态查看\n```\n查看FTP服务的端口号\n```shell\nnetstat -antup | grep ftp\n```\n## 增加一个系统用户\n`virftp`，所有虚拟用户都会映射到此用户后对文件系统进行读写操作\n```shell\n方法一（推荐）：\n#添加用户，用户登录时使用 nologin（禁止用此用户名登陆服务器）\nuseradd -s /sbin/nologin virftp\n\n#设置用户密码（明文密码一次成功，不需要二次确认）\n#这种方式虽然简单，但是通过history命令可以查到用户的密码，所以不安全。\necho \"123456\" | passwd --stdin virftp\n\n方法二：\n#添加用户，用户登录时使用nologin（禁止用此用户名登陆服务器）\nuseradd -s /sbin/nologin virftp\n\n#设置用户密码（执行命令后要输入两次密码）\npasswd virftp\n```\n## 配置vsftp主配置文件\n```shell\n#题外话：过滤配置文件注释后内容并查看（相当于 cat /etc/vsftpd/vsftpd.conf 不显示注释）\ngrep -v \"#\" /etc/vsftpd/vsftpd.conf\n\n#重命名vsftpd主配置文件为vsftpd.conf.bak（推荐）\nmv /etc/vsftpd/vsftpd.conf{,.bak}\n\n#或者备份vsftpd主配置文件\n#cp /etc/vsftpd/vsftpd.conf{,.bak}\n\n#新建vsftpd.conf并编辑\nvim /etc/vsftpd/vsftpd.conf\n\n#禁止匿名用户登录\nanonymous_enable=NO\n#允许本地用户登录\nlocal_enable=YES\n#启用虚拟账户 \nguest_enable=YES\n#把虚拟账户映射到系统账户virftp              \nguest_username=virftp\n#使用虚拟用户验证（PAM验证）新建文件/etc/pam.d/vsftpd.pam(默认验证文件是/etc/pam.d/vsftpd)\npam_service_name=vsftpd.pam\n#设置存放各虚拟用户配置文件的目录（此目录下与虚拟用户名相同的文件为它的配置文件）\nuser_config_dir=/etc/vsftpd/vsftpd_viruser\n#启用chroot时，虚拟用户根目录允许写入\nallow_writeable_chroot=YES\n#设置被动模式下，建立数据传输可使用的端口范围的最小值。\n#建议您把端口范围设置在一段比较高的范围内，例如50000~50010，有助于提高访问FTP服务器的安全性。\npasv_min_port=50000\n#设置被动模式下，建立数据传输可使用的端口范围的最大值。\npasv_max_port=50010\n```\n\n## 配置虚拟用户访问vsftpd服务\n```shell\n#创建虚拟用户密码文件(奇数行为帐号，偶数行为密码)\nvim /etc/vsftpd/vir_user\ntest01\npwd01\ntest02\npwd02\n```\n## 创建虚拟用户的根目录\n要保证虚拟用户映射的系统用户，对这个根目录有读写权限\n```shell\n#创建虚拟用户对应根目录\n#方法一（推荐）：\nmkdir -p /home/virftp/{test01,test02}\n\n#方法二：\nmkdir -p /home/virftp/test01 /home/virftp/test02\n\n###题外话###\n#1、使用mkdir在同目录下创建多个目录：\n# mkdir /tmp/{proc,etc,home,usr}\n\n#2、使用mkdir同时在多目录下创建多目录：\n# mkdir /tmp/{proc/{1,2,3},etc/{4,5,6},home/dir}\n```\n修改目录权限\n```shell\n#方法一（推荐）：\nchown -R virftp.virftp /home/virftp/{test01,test02}\n\n#方法二：\nchown -R virftp.virftp /home/virftp/test01\nchown -R virftp.virftp /home/virftp/test02\n```\n\n## 配置虚拟用户各自的配置文件\n```shell\n#创建‘虚拟用户配置文件’的存放目录\nmkdir /etc/vsftpd/vsftpd_viruser/\n\n#创建和配置虚拟用户各自的配置文件(文件名称是‘虚拟用户名’)\nvim /etc/vsftpd/vsftpd_viruser/test01\n# 指定虚拟用户的虚拟目录（虚拟用户登录后的主目录,即登录ftp后访问的根目录）\nlocal_root=/home/virftp/test01\n# 允许写入\nwrite_enable=YES\n#允许浏览FTP目录和下载\nanon_world_readable_only=NO\n#禁止用户下载\n#download_enable=NO\n# 允许虚拟用户上传文件\nanon_upload_enable=YES\n# 允许虚拟用户创建目录\nanon_mkdir_write_enable=YES\n# 允许虚拟用户执行其他操作（如改名、删除）\nanon_other_write_enable=YES\n# 上传文件的掩码,如022时，上传目录权限为755,文件权限为644\nanon_umask=022\n```\n## 生成虚拟用户数据库\n```shell\ndb_load -T -t hash -f /etc/vsftpd/vir_user /etc/vsftpd/vir_user.db\nchmod 700 /etc/vsftpd/vir_user.db\n```\n\n## 配置vsftpd验证文件\n默认验证文件 /etc/pam.d/vsftpd\n```shell\n方法一（推荐）：\n#新建验证文件\ntouch /etc/pam.d/vsftpd.pam\n\n### 题外话：创建10个文件，从test01.txt到test10.txt ###\n#touch /home/virftp/test02/test{01..10}.txt\n\n# 使用命令在文件后追加(-e 参数，把\\n当作换行处理，而不是当成字符串)\necho -e \"auth     required  pam_userdb.so  db=/etc/vsftpd/vir_user\\naccount  required  pam_userdb.so  db=/etc/vsftpd/vir_user\" >> /etc/pam.d/vsftpd.pam\n\n方法二：\n#新建验证文件，并添加如下两行\nvim /etc/pam.d/vsftpd.pam\nauth     required  pam_userdb.so  db=/etc/vsftpd/vir_user\naccount  required  pam_userdb.so  db=/etc/vsftpd/vir_user\n```\n## 重启服务\n```shell\nsystemctl restart vsftpd\n```\n## 总结\n若添加新虚拟用户，则需要做以下5件事：\n1、创建虚拟用户对应根目录文件夹并修改目录权限\n2、在/etc/vsftpd/vsftpd_viruser/目录下创建配置文件（文件名为虚拟用户名）\n3、在/etc/vsftpd/vir_user文件中添加帐号及密码\n4、再次执行生成虚拟用户数据库\n`db_load -T -t hash -f /etc/vsftpd/vir_user /etc/vsftpd/vir_user.db`\n5、重启vsftpd服务\n`systemctl restart vsftpd`\n\n异常问题\n1、为目录设置权限，不然无法对目录进行操作\n```chmod -R 777 /var/ftp/test2```\n2、将ftpuser添加到chroot_list中，连接ftp，提示530 Login incorrect，连接失败。但是创建的普通账号就可以正常登陆。\n\n解决方法：很多提供对系统非登录访问的守护进程（如FTP）会检查用户的登录shell是否列在/etc/shells中，如果没有列出，守护进程就会拒绝访问（这正是您所需要的动作）。\n\n打开 /etc/shells后，发现确实没有/sbin/nologin这一行，添加上再次登陆，成功。\n\n使用命令在文件后追加\n```shell\necho \"/sbin/nologin\" >> /etc/shells\n```\n\nvsftp配置文件及参数说明\n```\n/etc/vsftpd目录下文件说明如下：\n/etc/vsftpd/vsftpd.conf是vsftpd的核心配置文件。\n/etc/vsftpd/ftpusers是黑名单文件，此文件中的用户不允许访问FTP服务器。\n/etc/vsftpd/user_list是白名单文件，此文件中的用户允许访问FTP服务器。\n配置文件vsftpd.conf参数说明如下：\n用户登录控制参数说明如下表所示。\n参数    说明\nanonymous_enable=YES    接受匿名用户\nno_anon_password=YES    匿名用户login时不询问口令\nanon_root=（none）    匿名用户主目录\nlocal_enable=YES    接受本地用户\nlocal_root=（none）    本地用户主目录\n用户权限控制参数说明如下表所示。\n参数    说明\nwrite_enable=YES    可以上传文件（全局控制）\nlocal_umask=022    本地用户上传的文件权限\nfile_open_mode=0666    上传文件的权限配合umask使用\nanon_upload_enable=NO    匿名用户可以上传文件\nanon_mkdir_write_enable=NO    匿名用户可以建目录\nanon_other_write_enable=NO    匿名用户修改删除\nchown_username=lightwiter    匿名上传文件所属用户名\n```\n## 附件(sh执行文件)\n```sh\n#!/bin/sh\necho \"Centos7.6搭建和使用 vsftpd - 虚拟多用户配置\"\n\necho \"一、安装ftp服务\"\n\n#安装 vsftpd\nyum install -y vsftpd\n\n# 安装虚拟用户数据库(后面用到的 db_load 命令)\n#yum -y install libdb-utils\n\n#启动FTP服务。\nsystemctl start vsftpd.service\n\n#设置FTP服务开机自启动。\nsystemctl enable vsftpd.service\n\n#当前时间\nshijian=`date \"+%Y-%m-%d_%H:%M:%S\"`\n#系统用户\nsys_user=\"ljs\"\n#虚拟用户1\nvir_user_01=\"user01\"\nvir_pwd_01=\"pwd01\"\nvir_user_01_conf_filename=$vir_user_01\nvir_user_01_ftp_dir=\"/home/abc/ftp01\"\n#虚拟用户2\nvir_user_02=\"user02\"\nvir_pwd_02=\"pwd02\"\nvir_user_02_conf_filename=$vir_user_02\nvir_user_02_ftp_dir=\"/home/abc/ftp02\"\n#vsftpd服务配置文件\nftp_conf_file=\"/etc/vsftpd/vsftpd.conf\"\n#虚拟用户及密码文件\nvir_user_pwd_file=\"/etc/vsftpd/vir_user.pwd\"\n#虚拟用户配置文件的存放目录\nvir_user_conf_dir=\"/etc/vsftpd/vsftpd_viruser\"\n#设置被动模式下，建立数据传输可使用的端口范围的最小值、最大值。\npasv_min_port=50000\npasv_max_port=50010\n#虚拟用户验证文件\nverify_file=\"/etc/pam.d/vsftpd.pam\"\n#虚拟用户数据库文件\nvir_user_db_file=\"/etc/vsftpd/vir_user_database.db\"\n\necho \"二、增加一个系统用户${sys_user} ，所有虚拟用户都会映射到此用户后对文件系统进行读写操作\"\n\n#添加用户，用户登录时使用 nologin（表示禁止用此用户名登陆服务器）\nuseradd -s /sbin/nologin ${sys_user}\n\n#设置用户密码（明文密码一次成功，不需要二次确认）\n#这种方式虽然简单，但是通过history命令可以查到用户的密码，所以不安全。\necho \"123456\" | passwd --stdin ${sys_user}\n\necho \"三、配置vsftp主配置文件\"\n\n#重命名vsftpd主配置文件为 vsftpd.conf.bak（推荐）\nmv ${ftp_conf_file}{,.bak}\n\n#新建vsftpd.conf并编辑\ncat > ${ftp_conf_file} << EOF\n#文件生成时间\n#${shijian}\n#开启被动模式。\npasv_enable=YES\n#禁止匿名用户登录\nanonymous_enable=NO\n#允许本地用户登录\nlocal_enable=YES\n#启用虚拟账户 \nguest_enable=YES\n#把虚拟账户映射到系统账户${sys_user}\nguest_username=${sys_user}\n# guest_username=www\n# 如果ftp目录是指向网站根目录，用来上传网站程序，\n# 可以指定虚拟用户的宿主用户为nginx运行账户www，可以避免很多权限设置问题\n#使用虚拟用户验证（PAM验证）新建文件${verify_file}(默认验证文件是/etc/pam.d/vsftpd)\npam_service_name=$(basename $verify_file)\n#设置存放各虚拟用户配置文件的目录（此目录下与虚拟用户名相同的文件为它的配置文件）\nuser_config_dir=${vir_user_conf_dir}\n#启用chroot时，虚拟用户根目录允许写入\nallow_writeable_chroot=YES\n#设置被动模式下，建立数据传输可使用的端口范围的最小值。\n#建议您把端口范围设置在一段比较高的范围内，例如50000~50010，有助于提高访问FTP服务器的安全性。\npasv_min_port=${pasv_min_port}\n#设置被动模式下，建立数据传输可使用的端口范围的最大值。\npasv_max_port=${pasv_max_port}\nEOF\n\necho \"四、配置虚拟用户访问vsftpd服务\"\n\n#创建虚拟用户密码文件(奇数行为帐号，偶数行为密码)\ncat > ${vir_user_pwd_file} << EOF\n${vir_user_01}\n${vir_pwd_01}\n${vir_user_02}\n${vir_pwd_02}\nEOF\n\necho \"五、创建虚拟用户的根目录，要保证虚拟用户映射的系统用户，对这个根目录有读写权限\"\n\n#创建虚拟用户对应根目录\nmkdir -p {$vir_user_01_ftp_dir,$vir_user_02_ftp_dir}\n\n#修改目录权限\nchown -R ${sys_user}.${sys_user} {$vir_user_01_ftp_dir,$vir_user_02_ftp_dir}\n\necho \"六、配置虚拟用户各自的配置文件\"\n\n#创建‘虚拟用户配置文件’的存放目录(目录必须真实存在，不然无法使用cat EOF命令)\nmkdir ${vir_user_conf_dir}\n\n#创建和配置虚拟用户各自的配置文件(文件名称必须只能是‘虚拟用户名’,也不能有后缀)\ncat > ${vir_user_conf_dir}/${vir_user_01_conf_filename} << EOF\n# 指定虚拟用户的虚拟目录（虚拟用户登录后的主目录,即登录ftp后访问的根目录）\nlocal_root=${vir_user_01_ftp_dir}\n# 允许写入\nwrite_enable=YES\n#允许浏览FTP目录和下载\nanon_world_readable_only=NO\n#禁止用户下载\n#download_enable=NO\n# 允许虚拟用户上传文件\nanon_upload_enable=YES\n# 允许虚拟用户创建目录\nanon_mkdir_write_enable=YES\n# 允许虚拟用户执行其他操作（如改名、删除）\nanon_other_write_enable=YES\n# 上传文件的掩码,如022时，上传目录权限为755,文件权限为644\nanon_umask=022\nEOF\n\ncat > ${vir_user_conf_dir}/${vir_user_02_conf_filename} << EOF\n# 指定虚拟用户的虚拟目录（虚拟用户登录后的主目录,即登录ftp后访问的根目录）\nlocal_root=${vir_user_02_ftp_dir}\n# 允许写入\nwrite_enable=YES\n#允许浏览FTP目录和下载\nanon_world_readable_only=NO\n#禁止用户下载\n#download_enable=NO\n# 允许虚拟用户上传文件\nanon_upload_enable=YES\n# 允许虚拟用户创建目录\nanon_mkdir_write_enable=YES\n# 允许虚拟用户执行其他操作（如改名、删除）\nanon_other_write_enable=YES\n# 上传文件的掩码,如022时，上传目录权限为755,文件权限为644\nanon_umask=022\nEOF\n\necho \"七、生成虚拟用户数据库\"\ndb_load -T -t hash -f ${vir_user_pwd_file} ${vir_user_db_file}\nchmod 700 ${vir_user_db_file}\n\necho \"八、配置vsftpd验证文件（默认验证文件 /etc/pam.d/vsftpd）\"\n\n#新建验证文件并使用命令添加内容(-e 参数，把\\n当作换行处理，而不是当成字符串。> 表示清空再添加内容，>> 表示追加内容)\necho -e \"auth     required  pam_userdb.so  db=${vir_user_db_file%.*}\\naccount  required  pam_userdb.so  db=${vir_user_db_file%.*}\" > ${verify_file}\n\necho \"九、重启服务并查看vsftpd服务状态\"\nsystemctl restart vsftpd.service\nsystemctl status vsftpd.service\n```"},{"title":"linux配置-ssh","url":"/3362da68.html","content":"> 客户端A主机，服务端B主机。实现A主机通过免密登陆B主机\n\n## 在B主机安装ssh\n```shell\napt install -y openssh-server\n```\n<!-- more -->\n## 修改B主机的ssh配置文件\n```bash\n#1、#PermitRootLogin prohibit-password 改为 PermitRootLogin yes (允许root登陆ssh)\nsed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config\n#或者直接在文件末尾追加\necho \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n\n#2、如果想使用自定义的端口 可以设置 Port 9000\nsed -i 's/#Port 22/Port 9000/' /etc/ssh/sshd_config\n#或者直接在文件末尾追加\necho \"Port 9000\" >> /etc/ssh/sshd_config\n```\n## 配置B主机的管理员root密码\n```shell\npasswd root\n#或者用明文的方式配置密码\necho 'root:aaaa' | chpasswd\n```\n## 启动B主机的ssh服务\n```shell\nservice ssh start\n\n#配置好密码之后，直接在这个容器中尝试下连接\nssh root@127.0.0.1 -p 9000\n\n#宿主机上登陆ssh测试\n使用 docker inspect 容器id | grep '\"IPAddress\"' 查看容器的ip\nssh root@172.18.0.2 -p 9000\n```\n\n## 配置B主机实现ssh免密登陆\n先在客户端A主机上通过`ssh-keygen`命令生成密钥对\n> id_rsa 私钥，id_rsa.pub 公钥\n```shell\nroot@c86bf8bed861:/# ssh-keygen\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/root/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /root/.ssh/id_rsa\nYour public key has been saved in /root/.ssh/id_rsa.pub\n```\n通过scp命令将主机A上的id_rsa.pub公钥文件复制到远程主机B\n```shell\nscp -P 9000 /root/.ssh/id_rsa.pub root@81.110.26.20:/root/.ssh/\n#或者使用ssh-copy-id 直接在远程主机B对应的.ssh/文件夹下生成authorized_keys\nssh-copy-id -i ~/.ssh/id_rsa.pub -p 9000 root@81.110.26.20\n```\n> 9000是远程B主机81.110.26.20的ssh登陆端口，通过scp命令复制，前提是远程服务器已经开启ssh密码登录。\n\n### B主机配置\n\n1、将上传的公钥文件转换或重命名为 authorized_keys 文件\n```shell\n#如果上一步配置中使用了ssh-copy-id 此步可以省略\ncat /root/.ssh/id_rsa.pub >> /root/.ssh/authorized_keys\n```\n2、编辑主机B上的ssh的配置文件。\n```shell\nvim /etc/ssh/sshd_config\n\n#要确保下面这两项没有注释\nPubkeyAuthentication yes #允许公钥认证\nAuthorizedKeysFile .ssh/authorized_keys #指定包含用于用户身份验证的公钥的文件\n\n#为了安全考虑，可以禁用root账户登录（不禁用也不影响免密登陆），或者在选项前面可以加#号\nPermitRootLogin no\n\n#有了证书登录，可以禁用密码登录（不禁用也不影响免密登陆），或者在选项前面可以加#号\nPasswordAuthentication no\n```\n重启一下B主机的ssh服务，这样ssh配置免密登陆才能生效\n```shell\nservice ssh restart\nssh root@81.110.26.20 -p 9000 # 这时不需要密码就可以登陆了\n```\n\n## 总结\n1、在客户端A主机上创建密钥对，把公钥复制到ssh服务器B主机上，实现A免密登陆B。\n2、为了安全建议不要使用root用户，可以试试A、B两个服务器都使用普通用户。","tags":["ssh"],"categories":["linux"]},{"title":"rsync-sersync配置","url":"/c36c8db7.html","content":"<!-- toc -->\n## 创建数据源服务器\n<!-- more -->\n```shell\ndocker run -itd --name nginx-source -v /websource:/www -p 80:80 -p 443:443 -p 873:873 nginx\n```\n安装 rsync\n```shell\ndocker exec -it nginx-source bash\napt install rsync -y\n```\n\n## 创建密码文件\n> 只存在于源服务器上，文件只保存密码，并且只有一行，不要有用户名，像amdin:123456是不对的，只保存123456即可\n```shell\necho \"123456\" > /etc/rsync.verify\nchmod 600 /etc/rsync.verify\n```\n## 配置备份服务器\n> 需要与源服务器同步的多个服务器都按如下这样配置\n\n创建备份端服务器\n```shell\ndocker run -itd --name nginx-back -v /webback:/wwwback -p 81:80 -p 444:443 -p 874:873 nginx\n```\n\n在备份服务器上安装\n```shell\ndocker exec -it nginx-back bash\napt -y install rsync\n```\n### 创建rsyncd.conf配置文件\n> rsyncd.conf配置文件在备份服务器上\n```\n#设置运行rsync 进程的用户\nuid = root\n#运行进程的组\ngid = root\n#ip这里指本机ip，即备份服务器的ip，可以省略\n#address = 100.17.10.3\n#本机端口，这里是875服务器的端口，如888，870等等只要不被占用，防火墙开启就可以\nport = 873\n#如果\"use chroot\"指定为true，那么rsync在传输文件以前首先chroot到path参数所指定的目录下。这样做的原因是实现额外的安全防护，但是缺 点是需要以roots权限，并且不能备份指向外部的符号连接所指向的目录文件。默认情况下chroot值为true(或yes)。\nuse chroot = yes\n#最大连接数\nmax connections = 5\n#CentOS7中yum安装不需指定pid file 否则报错\n#pid file = /var/run/rsyncd.pid\nlock file=/var/run/rsyncd.lock\n#日志文件\nlog file = /var/log/rsyncd.log\n#不同步的文件\n#exclude = lost+found/\ntransfer logging = yes\n#超时时间\ntimeout = 900\n#同步时跳过没有权限的目录\nignore nonreadable = yes\n#传输时不压缩的文件\ndont compress = *.gz *.tgz *.zip *.z *.Z *.rpm *.deb *.bz2\n\n#规则模块，可以多个规则模块，不可以重名\n[wwwroot]\n#同步的路径提前在备份服务器中创建好\npath = /wwwback/\n#规则描述，随便写\ncomment = rsync test\n#忽略错误\nignore errors\n#是否可以pull 设置服务端文件读写权限\nread only = false\n#是否可以push\n#write only = false\n#不显示服务端资源列表\nlist = false\n#下面配置同步时候的身份，注意该身份是在rsync里面定义的，并非是本机实际用户。\n#客户端获取文件的身份此用户并不是本机中确实存在的用户\n#该选项指定由空格或逗号分隔的用户名列表，只有这些用户才允许连接该模块\nauth users = admin ljs\n#用来认证客户端的秘钥文件 格式 USERNAME:PASSWORD\n#秘钥文件权限一定需要改为600，这里配置填写的是备份服务器的账户文件。\nsecrets file = /etc/rsync.password\n#允许的主机访问 *代表所有\nhosts allow = *\n#创建rsyncd.conf配置文件 结束\n```\n原理：在备份服务器上使用配置文件 /etc/rsyncd.conf 来启动rsync，创建备份账户（像admin:123456的形式），最后把rsync以deamon方式运行（往下看有运行方法）\n\n> 自定义账户及密码，格式为user:password，每行一个\n这个用户是虚拟用户，不是系统用户，只是用来验证同步操作是否合法\n```shell\n# 新建并添加一行\necho \"admin:123456\" > /etc/rsync.password\n# 再增加一行\necho \"ljs:123456\" >> /etc/rsync.password\n#设置权限\nchmod 600 /etc/rsync.password\n```\n### 备份服务器上启动rsync\n```shell\n#加载备份服务器上的配置文件rsyncd.conf启动rsync服务\nrsync --daemon --config=/etc/rsyncd.conf\n#/etc/rsyncd.conf是缺省值，如果存在，则命令可以简写\nrsync --daemon\n```\n## 备份测试\n> 备份命令（在源服务器上执行同步命令）\n把源服务器上的文件复制到备份服务器上\n```shell\n# 注意：/www/ 表示同步www目录下的文件和文件夹，/www表示把www文件夹也同步过去\nrsync -avz /www/ admin@100.17.10.3::wwwroot\n\n# --delete 表示当备份服务器上有，而源服务器上没有的文件，在同步时会被删除\nrsync -avz --delete /www/ admin@100.17.10.3::wwwroot\n\n#后面的 --password-file=/etc/rsync.verify 就是源服务器上的密码验证文件\n#此验证文件只存在源服务器上，记得开启600权限。\n#如果不加此参数项，则要求自行输入密码123456\nrsync -avz --delete /www/ admin@100.17.10.3::wwwroot --password-file=/etc/rsync.verify\n\n#不需要同步的文件和目录可以加上参数 --exclude\nrsync -avz /www/ --exclude=\".svn\" --exclude=\"bbb\" admin@100.17.10.3::wwwroot\n\nrsync -vzrtopg --progress /www/ admin@100.17.10.3::wwwroot --password-file=/etc/rsync.verify\n```\n到这里linux的rsync同步就配置成功了，接下来再介绍一款网上比较推荐的一个软件，rsync搭配sersync一起使用。\n## 配置sersync\n> 在源服务器上进行sersync的配置\n\n1、上传sersync2.5.4_64bit_binary_stable_final.tar.gz到源服务器 /usr/local/ 目录下\n```shell\ncd /usr/local\n\n#解压后在当前目录中会有一个 GNU-Linux-x86 文件夹\ntar xvf sersync2.5.4_64bit_binary_stable_final.tar.gz\n\n#文件夹名字改成sersync,里面有两个文件,一个是二进制文件sersync2 ,一个是配置文件confxml.xml\nmv GNU-Linux-x86 sersync\n```\n2、修改confxml.xml\n```\n#修改sersync部分\n<sersync>\n    #本地同步目录 监控源服务器上的目录变化\n    <localpath watch=\"/www/\">\n        #rsync模块名称,可以配置多个\n        <remote ip=\"100.17.10.3\" name=\"wwwroot\"/>\n        <!--<remote ip=\"100.17.10.3\" name=\"tongbu\"/>-->\n        <!--<remote ip=\"130.170.10.31\" name=\"py\"/>-->\n    </localpath>\n    #修改rsync认证部分【rsync密码认证】\n    <rsync>\n        <commonParams params=\"-artuz\"/>\n        <auth start=\"true\" users=\"admin\" passwordfile=\"/etc/rsync.verify\"/>\n        <userDefinedPort start=\"false\" port=\"874\"/><!-- port=874 -->\n        <timeout start=\"false\" time=\"100\"/><!-- timeout=100 -->\n        <ssh start=\"false\"/>\n    </rsync>\n</sersync>\n```\n3、配置sersync开启sersync守护进程同步数据（运行如下命令）\n```shell\n/usr/local/sersync/sersync2 -d -r -o /usr/local/sersync/confxml.xml\n\n# -o 指定/usr/local/sersync/confxml.xml作为配置文件\n# -r 在实时监控前作一次整体同步\n# -d 以守护进程方式在后台运行\n```\n4、测试\n在源服务器上（watch=\"/www/\"）目录下添加文件 看备份服务器上有没有变化\n5、sersync 参数项详解\n```\n/usr/local/sersync/sersync2 -help\nset the system param\nexecute：echo 50000000 > /proc/sys/fs/inotify/max_user_watches\nexecute：echo 327679 > /proc/sys/fs/inotify/max_queued_events\nparse the command param\n_______________________________________________________\n参数-d:启用守护进程模式\n参数-r:在监控前，将监控目录与远程主机用rsync命令推送一遍\nc参数-n: 指定开启守护线程的数量，默认为10个\n参数-o:指定配置文件，默认使用confxml.xml文件\n参数-m:单独启用其他模块，使用 -m refreshCDN 开启刷新CDN模块\n参数-m:单独启用其他模块，使用 -m socket 开启socket模块\n参数-m:单独启用其他模块，使用 -m http 开启http模块\n不加-m参数，则默认执行同步程序\n\n#例如：\n./sersync2 -n 8 -o abc.xml -r -d\n#表示，设置线程池工作线程为8个，指定abc.xml作为配置文件，在实时监控前作一次整体同步，以守护进程方式在后台运行。\n```\n\n## 总结\n> 1、源服务器上安装 sersync和rsync，其中rsync不需要配置文件/etc/rsyncd.conf，不需要后台运行，不需要用户名密码表文件/etc/rsync.password。sersync只需要配置文件confxml.xml和rsync密码验证文件/etc/rsync.verify\n\n> 2、备份服务器上只安装rsync，只需要配置文件rsyncd.conf和用户名密码表/etc/rsync.password","tags":["sync","rsync","sersync"],"categories":["linux"]},{"title":"python 备份文件到百度网盘的方法","url":"/40df1f5.html","content":"这里是摘要，linux 与 百度网盘。这里推荐一款python 插件 bypy。\n<!-- more -->\n### linux 与 百度网盘同步\nhttps://github.com/houtianze/bypy\n\n#环境：\ncentos release 7.9\npython 2.7.5\n\n### 先下载并安装pip\n针对python 2.7版本\n```shell\ncurl -O https://bootstrap.pypa.io/pip/2.7/get-pip.py\n```\n针对python 3.x版本\n```shell\ncurl -O https://bootstrap.pypa.io/get-pip.py # curl方式\nwget https://bootstrap.pypa.io/get-pip.py # wget方式\npython get-pip.py\n```\n升级pip\n```shell\npython -m pip install --upgrade pip\n```\n\n### 使用 pip 安装 bypy\n```shell\npip install bypy\n```\n### 使用 pip 升级 bypy\n```shell\npip install -U bypy\n```\n\n### 运行\n1,作为独立程序: 运行 bypy (或者python -m bypy，或者python3 -m bypy）\n\n2,作为一个包，在代码中使用: import bypy\n\n### 授权\n#随便执行一个bypy命令，例如bypy info 会返回以下内容（此步操作只针对第一次使用时）\n[root@hostlocal ~]# bypy info\nPlease visit:  \nhttps://openapi.baidu.com/oauth/2.0/authorize?scope=basic+netdisk&redirect_uri=oob&response_type=code&client_id=q8WE4EpCsau1oS0MplgMKNBn\nAnd authorize this app\nPaste the Authorization Code here within 10 minutes.\nPress [Enter] when you are done\n#用浏览器访问上面的链接获取授权码，然后粘贴再回车就授权成功.\n\n### 常用命令\n#创建云盘目录（测试中发现，云盘中没有目录，在使用 upload 和 syncup 会自动创建）\nbypy mkdir <remotedir>\nbypy mkdir bbb/ccc/ddd 和 bypy mkdir /bbb/ccc/ddd 结果是一样的，都是在程序文件夹（bypy）下生成多级目录\n\n#上传文件(如果后面不加任何参数，在某个文件夹下就会将文件夹下的内容全部上传到云端程序文件夹（bypy）下)\nbypy upload [localpath] [remotepath] [ondup] （如果本地路径中有空文件夹，则不会上传到云盘）\n例如 bypy upload /root/ljs /aaa overwrite\n[ondup]的值有'overwrite', 'skip', 'prompt' 分别是 “覆盖”,“跳过”,“提示”(缺省值:覆盖)\n\nbypy syncup [localdir] [remotedir] [deleteremote] （可以上传空文件夹）\n例如 bypy syncup /root/ljs /aaa\n\n### upload 和 syncup 的区别\n> 1、如果没有第3个参数，暂时在测试中发现，它俩的功能是一样的\n> 2、upload 会返回同步的详情信息，而 syncup 不会返回信息\n> 3、upload 不会上传空文件夹，而 syncup 可以上传空文件夹\n> 4、upload 可以同步目录或单个文件，而 syncup 只同步目录\n\n#下载文件\nbypy syncdown [remotedir] [localdir] [deletelocal] - 从远程目录同步到本地目录中\nbypy downdir [remotedir] [localdir] - 下载远程目录(递归)\nbypy downfile <remotefile> [localpath] - 下载远程文件\nbypy download [remotepath] [localpath] - 下载一个远程目录/文件(递归)\n\n### 其它\n```shell\n#启动bypy可能会缺少的模块\nyum install python-urllib3 python-requests\n\n#Debian / Ubuntu 环境下，只需执行如下命令一次：\npip install requests\n```\n","tags":["python","sync"]},{"title":"docker镜像与容器打包及上传到仓库","url":"/f255ffad.html","content":"https://docs.docker.com/engine/reference/commandline/build/\n\n### 用容器生成镜像\n```shell\ndocker commit -a \"oner\" -m \"aaa123\" 38731354b329 wpa:1.0\n```\n> -a 为作者\n> -m 为描述信息\n> 38731354b329 运行中的容器的ID\n> wpa:1.0 生成镜像名:版本号\n<!-- more -->\n### 为本地镜像设置新标签tag\n在上传之前，先给本地镜像打个tag标签，相当于重新复制镜像并重命名为docker账户名/仓库名称:新标签名\n```\n#docker tag 本地镜像:tagname docker账号/docker仓库:tagname\ndocker tag centos:7 xxx/centos:7.9\n# 还可以\ndocker tag centos:7 xxx/linuxos:centos-v7\n```\n### 登录docker仓库\n\ndocker login\nUsername: xxx\nPassword: yyy\nLogin Succeeded\n\n### 上传本地镜像到镜像仓库\n```\n#docker push docker 账号/仓库名称:tagname\ndocker push xxx/linuxos:centos-v7\n```\n### 将一个或多个镜像打包\n> /diyimages/目录要事先存在\n> 如果不指定镜像的标签tag，会将此镜像的所有标签tag全部打包\n\n```shell\ndocker image save nginxsync:1.0 php-fpm > /diyimages/nginxdiy.tar\n\n# 或者\n#docker save -o /diyimages/nginxdiy.tar nginxsync:1.0 php-fpm\n\n# 或者 使用 gzip 压缩\n#docker save nginxsync:1.0 php-fpm | gzip > /diyimages/myimage_latest.tar.gz\n\n```\n\n### 导入镜像文件\n\n```shell\ndocker image load < /diyimages/nginxdiy.tar\n\n# 或者\n#docker load -i /diyimages/nginxdiy.tar\n\n#导入的镜像id也与之前一样\n```\n### 其它容器命令\n```shell\n#输出所有容器的id\ndocker ps -a -q\n\n#强制删除容器(包括正在运行的)\ndocker rm -f 容器名或id\n\n#强制删除所有容器(包括正在运行的)\ndocker rm -f $(docker ps -a -q)\n```\n\n### 在容器外操作容器内的命令\n```shell\n# 先创建一个容器\ndocker run -itd --name ngtest --hostname nghost nginx:1.24.0\n\n# nginx\ndocker exec -it ngtest /bin/bash -c 'cd /home; echo \"hi, I am in docker\"'\n\ndocker exec -it ngtest /bin/bash -c 'nginx -s reload'\n\ndocker exec -it ngtest /bin/bash -c 'service nginx status'\n\n# php-fpm\ndocker exec -it phpfpm4 /bin/bash -c 'supervisord -c /www/supervisor_php.conf'\n\n```","tags":["docker"],"categories":["docker"]},{"title":"hexo配置研究","url":"/7f79bcde.html","content":"## 第一次使用hexo\n\n### 快速使用\n```bash\nnpm install hexo-cli -g # 全局安装模块\nhexo init /hexo # 新建并初始化项目目录\ncd /hexo\nnpm install\nhexo server # 简写：hexo s\n```\n然后就可以通过 http://ip:4000 打开你的hexo博客了\n\n<!-- more -->\n\n> 注意：以下是使用 alpine hexo 容器进行建站\n\n```shell\n~/.hexo $ hexo -v\nINFO  Validating config\nhexo: 6.3.0\nhexo-cli: 4.3.1\nos: linux 5.10.0-15-amd64 Alpine Linux\nnode: 18.17.0\n\n~/.hexo $ npm -v\n9.6.6\n\n~/.hexo $ cat /etc/alpine-release\n3.18.3\n\n```\n\n## 所有者不是 hexo 的问题\n1、遇到过编辑文章时，无法保存，服务也不可访问的情况。\n\n2、开启 hexo-abbrlink 也是服务无法访问。\n\n3、hexo-admin 后台看不到文章。\n\n研究发现：文章的所有者不是 hexo 需要修改成 hexo，对应的uid为1000\n\n```shell\n# 修改文件所有者(在宿主机或者容器中以root用户进入执行命令)\nchown 新所有者名或uid 待修改权限的文件或者目录\n\n# 修改单个文件的所有者\nchown 1000 test.md\n\n# -R 表示递归，批量修改 _posts 目录自身以及其下的所有子目录和子文件的所有者\nchown -R 1000 _posts\n\n#以root用户进入容器，执行命令\ndocker exec -it -u root my_hexo sh\nchown -R hexo .\n\n#如果不是使用hexo用户执行以上命令，每次操作后都要修改权限（修改目录及文件的所有者为hexo,对应的uid为1000）\n#注意在宿主机中执行命令，uid 1000 对应的可能是别的用户名，比如：admin。\n#此时你通过ftp查看容器映射到宿主机的文件时，所有者会显示为admin。\n#其实容器中显示的是hexo，因为uid 1000在容器中对应的就是hexo用户。\nchown -R 1000 .\n\n```\n> 进入容器，使用hexo用户操作文件或文件夹时所有者就是 hexo，就不会存在此问题。\n\n## hexo 内容管理后台\n```shell\nnpm install hexo-admin\n```\n然后就可以通过 http://ip:4000/admin 打开你的hexo博客后台了\n\n## 使用 hexo-admin 后台执行 deploy\n\n在 /hexo 目录下新建 hexo_deploy.sh 文件代码内容如下：\n```\n#!/usr/bin/env sh\nhexo clean\nhexo g\nhexo d\n```\n修改 /hexo/_config.yml 文件，添加以下内容\n```\n# hexo-admin 使用用户:ljs 和密码:ljsljs 登录\nadmin:\n  #username: ljs\n  #password_hash: $2a$10$/CFpA2l/UkaHwCPfGus1JuLhZt4vJu1LDTppN39dEgayA0a0Yleqy\n  #secret: fdasf789$$%@%@$#\n  deployCommand: './hexo_deploy.sh'\n```\n> 以上完成后，在 http://ip:4000/admin/#/deploy 页面下 点击 deploy 按钮，就可以运行 hexo_deploy.sh\n\n## 自动生成目录\n如果想让博文自动生成文章目录 需要安装 hexo-toc 插件（有的主题会自带生成目录的功能，像stun）\n```shell\nnpm install hexo-toc\n```\n然后使用以下标签，写在需要生成目录的位置，一般是放在文章内容顶部\n```html\n<!-- toc -->\n```\n安装后如果没有生效，重启hexo服务\n\n## 生成永久链接地址\n原理是为 *.md 添加一个标签 abbrlink: 123456\n\n在文章（*.md）修改时（包括文件名和文章内容），插件生成的 abbrlink 值前后都是一样的，相当于生成了一个固定的唯一的url永久地址。\n\n插件 [hexo-abbrlink](https://github.com/rozbo/hexo-abbrlink) 生成字母和数字组合\n\n插件 [hexo-abbrlink2](https://github.com/rozbo/hexo-abbrlink2) 生成递增的数字\n```shell\n# 安装插件\nnpm install hexo-abbrlink\nnpm install hexo-abbrlink2\n\n# 修改 /hexo/_config.yml文件\n# 不带 .html 后缀\n#permalink: posts/:abbrlink/\n# 带 .html 后缀\npermalink: posts/:abbrlink.html\nabbrlink:\n  #hexo-abbrlink 设置\n  alg: crc32   #算法： crc16(default) and crc32(推荐)\n  rep: hex     #进制： dec(default) and hex(推荐)\n  #hexo-abbrlink2 设置\n  #start: 1000 # the first id, default 0\n```\n\n## 安装主题\n```shell\ncd /hexo\ngit clone https://github.com/liuyib/hexo-theme-stun.git themes/stun\nnpm install hexo-renderer-pug\n```\n\n找到 /hexo/_config.yml 文件 修改主题为 stun\n```/hexo/_config.yml\ntheme: stun\n```\n\n## 安装本地搜索插件\n\n在 /hexo 下安装本地搜索插件：\n```shell\nnpm install hexo-generator-search\n```\n配置插件，找到 /hexo/_config.yml 文件，添加以下字段：\n```/hexo/_config.yml\nsearch:\n  path: search.json\n  field: post\n  content: true\n```\n生成数据，安装上述插件后，在 /hexo 下执行指令：\n```shell\nhexo g\n```\n这样会在 /hexo/public 下生成 search.json 文件，Stun 主题的本地搜索功能就是利用这个文件里的数据实现的。\n\n修改主题配置文件 /hexo/source/_data/stun.yml\n```/hexo/source/_data/stun.yml\nlocal_search:\n  enable: true\n```\n\n## 安装网站地图插件\n网站地图 https://github.com/hexojs/hexo-generator-sitemap\n在帖子/页面的*.md文件中添加 sitemap: false 参数, 可以排除帖子/页面不生成地图。\n\n```\nnpm install hexo-generator-sitemap --save\n```\n配置插件，找到 /hexo/_config.yml 文件，添加以下字段：\n```/hexo/_config.yml\nsitemap:\n  path:\n    - sitemap.xml\n    - sitemap.txt\n  template: ./diy/sitemap/sitemap_template.xml\n  template_txt: ./diy/sitemap/sitemap_template.txt\n  rel: false\n  tags: true\n  categories: true\n```\n\n## 安装pwa插件\n\n在 /hexo 下安装pwa插件：\n```shell\nnpm install hexo-pwa\n```\n配置插件\nhttps://theme-stun.github.io/docs/zh-CN/advanced/third-part.html#pwa\nhttps://github.com/lavas-project/hexo-pwa\n\n\n## 安装 hexo deploy 部署插件\n```shell\nnpm install hexo-deployer-rsync\nnpm install hexo-deployer-git\n```\n### hexo-deployer-rsync 插件的使用\n> 执行 hexo d 发布 public 目录下的静态文件到nginx服务器\n> 必须是ssh免密登陆，不然每次还需要输入远程服务器的密码\n\n```\n# 需要使用 root 用户进入容器，不然没有权限安装\ndocker exec -it --user root hexo sh\n\n# 安装 rsync 和 openssh\napk update\napk add --update --no-cache rsync openssh\n\n# 在 hexo 容器中执行，默认3次回车生成公钥和私钥文件\n# 记清楚你是使用 哪个用户 运行，例如使用 hexo 用户\nssh-keygen\n\n# 拷贝容器公钥文件到远程服务器上\n# 如果你是使用 hexo 用户运行 ssh-keygen 命令，则执行以下代码：\n# 需要输入一次远程服务器 45.77.216.11 的登录密码\nssh-copy-id -i /home/hexo/.ssh/id_rsa.pub root@45.77.216.11\n# 如果出现错误 删除 /home/hexo/.ssh/known_hosts 文件即可\nrm /home/hexo/.ssh/known_hosts\n```\n### hexo-deployer-git 插件的使用\n```shell\n# 新建 github.com 仓库名 wenyamu.github.io\n\n# 设置 ssh key\nssh-keygen -t rsa\n# 默认生成公钥的位置\n#/home/hexo/.ssh/id_rsa.pub\n\n#打开 id_rsa.pub 并复制公钥，在 GitHub 中新增一个 ssh key\n#类型 选择 Authentication Key\n#标题 随便写一个\n\n# 全局部署 GitHub 用户名和邮箱，让 GitHub 知道你是谁。\ngit config --global user.email xxx@gmail.com\ngit config --global user.name yyy\n\n```\n\n修改 /hexo/_config.yml 配置文件，一般在最底部\n```\ndeploy:\n# 上传到 nginx 服务器\n- type: rsync                 # 发布方式\n  host: 45.77.216.11          # nginx服务器ip\n  user: root                  # ssh登陆用户名\n  root: /usr/share/nginx/html # nginx服务器的静态文件目录\n  port: 22                    # ssh登陆端口\n  delete: true                # 本地public目录中没有，而ssh服务器上有的文件，则被删除\n  progress: true              # 显示rsync进展\n  args: \"\"                    # rsync 参数\n  rsh: \"\"                     # 指定要使用的远程shell\n  key: \"\"                     # 定制的SSH私有密钥\n  verbose: false              # 是否显示文件上传详细信息\n  ignore_errors: false        # 是否忽略错误提示\n  create_before_update: false # 首先创建不存在的文件,然后更新现有的文件\n# 上传到 github.com 使用 https://wenyamu.github.io/ 访问页面\n- type: git\n  repo: git@github.com:wenyamu/wenyamu.github.io.git\n  branch: master\n```\n\n## 让 .md 文件名称与文章标题一致\n> 替换 abc.md 文件中的 title: 字段的值为 abc\n> 因为 hexo 文章的标题是根据 .md 文件中的 title 字段的值作为标题\n\n新建 /hexo/retitle.js\n```js\n/**\n ** 替换 abc.md 文件中的 title: 字段的值为 abc\n ** 因为 hexo 文章的标题是根据 .md 文件中的 title 字段的值作为标题\n ** 修改 .md 的文件名称很方便 但是 title 字段的值不方便修改\n **\n\n// 对单个文件操作\nconst fs = require('fs');\nconst filePath = './path/to/123456.md';\nconst fileData = fs.readFileSync(filePath, { encoding: 'utf8' });\n\nvar RegExp=/(title:\\s*)(.*)/g; // 匹配 .md 文件中 title: 后面的参数值\n\nif(RegExp.test(fileData)){ //如果匹配到`title`字段\n  var title = fileData.match(RegExp)[0]; // 匹配结果返回 title: aaaa\n  var name  = title.substr(7); // 得到 title 参数值 aaa\n  console.log(title);\n  console.log(name);\n\n  // 替换 title 参数值（只替换从文件顶部开始匹配到的第一个）\n  const modifiedData = fileData.replace(name, 'bar');\n\n  // 将修改后的数据写回到文件中\n  fs.writeFileSync(filePath, modifiedData);\n  //console.log('数据已修改');\n}\n*/\n\n/* 对文件夹下的每个文件 操作*/\n\n//引入fs操作文件\nvar fs = require('fs');\nvar join = require('path').join;\n\n// 设置要操作的文件夹\nvar dirpath = \"./source/_posts/\";\n\nfunction getAllFiles(dir){\n  let jsonFiles = [];\n  function findJsonFile(path){\n    let files = fs.readdirSync(path);\n    files.forEach(function (item, index) {\n      let fPath = join(path,item);\n      let stat = fs.statSync(fPath);\n      if(stat.isDirectory() === true) {\n        findJsonFile(fPath);\n      }\n      if (stat.isFile() === true) { \n        jsonFiles.push(fPath);\n      }\n    });\n  }\n  findJsonFile(dir);\n  //console.log(jsonFiles);//指定目录下的文件，包括子目录\n  return jsonFiles;\n}\n\nfunction doFileEdit(){\n  // 文件夹下每个文件的路径json数据\n  var filesPathJson = getAllFiles(dirpath);\n  //console.log(filesPathJson);\n  for(var i=0; i < filesPathJson.length; i++){\n    var _file = filesPathJson[i]; // path/to/123456.md\n\n    var filename = _file.substr(_file.lastIndexOf('/')+1); // 123456.md\n    var md_name  = filename.slice(0,-3); // 123456\n    //console.log(md_name);\n\n    var fileData = fs.readFileSync(_file, { encoding: 'utf8' });\n    \n    // 匹配 .md 文件中 title: 后面的参数值(.md 文件中 冒号后面有空格)\n    var RegExp=/(title:\\s*)(.*)/g;\n\n    if(RegExp.test(fileData)){ //如果匹配到`title`字段\n      var md_title_str = fileData.match(RegExp)[0]; // 返回 title: aaaa\n      var md_title_var  = md_title_str.substr(7); // 返回 title 参数值 aaa\n      //console.log(md_title_str);\n      //console.log(md_title_var);\n      \n      // 如果 .md 文件中的 title 参数值 与 .md 文件名称不一致，则修改\n      if(md_title_var != md_name){\n        \n        console.log(\n        \"\\x1B[35m\"\n        + filename\n        + \"\\x1B[0m\"\n        + \"  \"\n        + md_title_str\n        + \"\\x1B[32m ===> \\x1B[0m\"\n        + \"\\x1B[36m\"\n        + md_name\n        + \"\\x1B[0m\"\n        );\n\n        // 替换 title 参数值（只替换从文件顶部开始匹配到的第一个）\n        var modifiedData = fileData.replace(md_title_var, md_name);\n\n        // 将修改后的数据写回到文件中\n        fs.writeFileSync(_file, modifiedData);\n      }\n    }\n  }\n}\n\nconsole.log(\"\\x1B[1m ---修改文件列表--- \\x1B[0m\");\ndoFileEdit();\n\n```\n先执行 node retitle.js\n再执行 hexo g \n\n## hexo 常用命令\n\n```shell\n# 初始化\nhexo init\n\n# 启动 Hexo 服务器\nhexo server\n\n# 清除缓存文件 (db.json) 和已生成的静态文件 (public)\nhexo clean\n\n# 生成全局静态文件\nhexo g\n\n#生成静态文件并部署\nhexo g -d\n\n# 部署\nhexo d\n\n# 部署前生成静态文件\nhexo d -g\n\n# 显示 Hexo 版本\nhexo version\n\n```\n然后项目目录下会生成一个 public 文件夹，静态文件都在其中，最后就可以布署到nginx服务器上了。"},{"title":"一文搞懂 flask gunicorn supervisor 的作用和关系","url":"/15af28d0.html","content":"- 使用 flask 搭建 python 网页应用\n> Flask是一个使用 Python 编写的轻量级 Web 应用框架\n类似于`Laravel`是使用 PHP 编写的 Web 应用框架\n- 使用 gunicorn 作为 flask 的 http 服务器\n> Gunicorn是一个专用于 python 的 http 服务器\n类似于`nginx`是常用于 html 的 http 服务器\n- supervisor 管理进程\n> supervisor 把其它应用的进程作为其子进程进行管理，还可以管理远程服务器上的进程\n> https://github.com/wenyamu/python_demo\n\n<!-- more -->\n\n## 创建 python 环境\n> docker compose -f python.yml up -d\n```yml\nversion: '3'\nservices:\n  dc1:\n    # 镜像本地无则自动下载\n    image: python:alpine\n    hostname: pythonHost\n    # 映射端口 【宿主机端口:容器端口】\n    ports:\n      - \"5000:5000\"\n      - \"8000:8000\"\n      - \"80:80\"\n      - \"443:443\"\n    # 目录挂载 【宿主机目录:容器目录】\n    volumes:\n      - /root/python:/python\n\n    # 容器名称\n    container_name: pythontest\n    #environment:\n    #  - \"SERSYNC=true\"\n    restart: always\n    # 相当于 docker run -i\n    stdin_open: true\n    # 相当于 docker run -t\n    tty: true\n```\n> 查看 python 和 pip 版本\n```shell\n#查看 python 版本\npython --version\nPython 3.11.4\n\n#查看 pip 版本\npip --version\npip 23.1.2 from /usr/local/lib/python3.11/site-packages/pip (python 3.11)\n\n#pip 升级\npip install --upgrade pip\n```\n> 安装程序运行用到的包\n```shell\npip install gunicorn flask gevent pymysql\n```\n\n## flask 项目目录结构\n```\n/\n-- python\n---- flasktest.py\n---- gconf80.py\n---- templates\n------ index.html\n\n```\n\n> 新建 /python/flasktest.py\n\n```py\nfrom flask import Flask, render_template, url_for, request\nimport pymysql\napp = Flask(__name__,\n  template_folder='/python/templates',\n  static_folder='/python/asset',\n  static_url_path=\"/\",\n  )\n\n@app.route('/')\ndef index():\n  return render_template('index.html', title='python',info=\"flask web app\")\n\n#以下命令，只有在使用 python this.py 才起作用\nif __name__=='__main__':\n  app.run(debug=True,host='0.0.0.0',port=5000)\n\n```\n> 代码段设置的解释\n```\napp = Flask(__name__,\n  template_folder='/python/templates',\n  static_folder='/python/asset',\n  static_url_path=\"/\",\n  )\n\n# __name__ 本文件的文件名（不含后缀）\n\n# template_folder 存放模板的目录，缺省值为当前项目目录下的templates目录\n\n# static_folder 存放静态文件的目录（注意：存放在此目录下的文件，都会被当成静态文件处理，\n例如php、py文件），通常存放css/js/jpg/html等文件（假设项目的绝对路径为\"/py\",\n如果参数值为\"/py/sss\"时，可以直接通过xxx.com/sss/x.jpg 进行访问，此时static_folder的值\n做为存放目录以及url访问），缺省值为当前项目目录下的static目录\n\n# static_url_path 访问静态文件的路由设置，可以配合static_folder使用，\n例如：当static_url_path参数值为\"/aaa\"时，可以直接通过xxx.com/aaa/x.jpg 进行访问，\n此时static_folder的值仅做为存放目录，不作为url访问\n```\n\n> 新建 /python/templates/index.html\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>{{ title }}</title>\n</head>\n<body>\n    <h1>欢迎来到 {{info}} ，我是一个模板文件</h1>\n\n</body>\n</html>\n\n```\n### 启动 flask 应用\n\n```shell\n# 进入项目根目录\ncd /python\n\n# 使用 python 启动 flask 应用(仅用于开发环境)\npython flasktest.py\n\n# 使用 gunicorn 启动 flask 应用\ngunicorn -w 4 -b 0.0.0.0:5000 flasktest:app\n```\n\n> 使用 ip:5000 访问 得到如下结果\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>python</title>\n</head>\n<body>\n    <h1>欢迎来到 flask web app ，我是一个模板文件</h1>\n\n</body>\n</html>\n```\n## gunicorn 启动 flask 应用\n> gunicorn 作用类似于 nginx，只不过它是专用于 python 的 http 服务器\n\n```shell\n# gunicorn 命令详解\ngunicorn -w 4 -b 0.0.0.0:5000 -b [::]:5000 --reload flasktest:app\n\n#flasktest:app flasktest指的是flasktest.py, app指的是flasktest.py中的app=Flask(...)\n#-w 指启动的进程数\n#-b 指绑定ip:端口号, 如果是本地端口 127.0.0.1:80 对应ipv6是 [::1]:80\n#--reload 代码更新时将热载入（模板更新时，测试发现不太稳定，时好时坏，建议手动重启应用）\n\n# 推荐把 gunicorn 的参数集中放入一个配置文件中(跟 nginx 启动一样，也是需要配置文件)\ngunicorn -c /python/gconf80.py flasktest:app --preload\n\n# --preload 运行前先检查是否有错误，有则直接输出错误信息\n```\n### gconf80.py 配置文件\n```python\n#gconf80.py 内容开始 与 gconf443.py 相比，端口80改成443，多了ssl配置\n\nfrom gevent import monkey\nmonkey.patch_all()\nimport multiprocessing\n#debug = True # 调试模式运行\ndaemon = False # 守护Gunicorn进程，默认False(即不让其在后台运行，而是使用supervisor管理进程)\n# True，表示代码更新时将被热载入（不用手动重启进程了）。如果是直接运行gunicorn命令，直接加参数 --reload 即可\nreload = True\n#绑定与Nginx通信的端口ipv4、ipv6\nbind = '0.0.0.0:80'\nbind = '[::]:80'\nworkers = multiprocessing.cpu_count()\n#workers = 3\n#默认为sync阻塞模式，最好选择gevent模式，需要安装gevent模块\n#Flask+gevent高效部署（基于gevent模块实现并发）：适用于io访问频繁的项目(比如对数据库的读写, 发送Http请求等等)，算法类型不适用\nworker_class = 'gevent'\n\n#设置环境变量(key=value)，将变量传递给flask\n'''\n# flask.py 中调用变量\nimport os\nos.getenv('ljs1')\n'''\nraw_env=[\"ljs1=111\",\"ljs2=bbb\"]\n\n#gunicorn 配置 ssl\n#keyfile = '/python/689890/privkey.pem'\n#certfile = '/python/689890/fullchain.pem'\n\n#gconf80.py 内容结束\n```\n### gunicorn 的 gevent 模式\n- 单进程直接运行 python http 服务时, 当有两个并发请求过来时, 进程只能先处理一个请求, 等第一个请求处理完成后, 才能处理第二个, 势必影响用户的体验。\n\n- 那么单进程的时候, 如何能提高并发处理能力？\n\n- 大多数情况下, 我们的服务中, 导致性能低下的原因是I/O, 比如对数据库的读写, 发送 http 请求等等, 当进程进行I/O的时候, 是不占用CPU时间的, 这个时候, CPU可以被腾出来处理其他请求。\n\n- gevent 就是完成这个工作的。幸运的是, 我们不需要自己实现这部分功能, gunicorn 实现了 gevent 模式的运行方式(-k 参数指定), 允许你的 python web 更高性能的处理业务，例如：\n\n```shell\ngunicorn \\\n    -k gevent \\\n    -w 2 \\\n    -b 127.0.0.1:9889 \\\n    run:app\n```\n\n\n## supervisor 项目目录结构\n```\n/\n-- python\n---- flasktest.py\n---- supervisor_flaskapp.conf\n---- gconf80.py\n---- supervisor_conf\n------ flask80.conf\n---- templates\n------ index.html\n\n```\n### 各文件的功能说明\n\nflasktest.py\n> web程序文件，是用 python 写的 web 页的功能代码。类似于 php 写的 web 页 xxx.php 文件是一个意思。\n\ngconf80.py\n> 作为启动 gunicorn 的配置文件，对 gunicorn 的监听端口，线程数等参数进行设置。\n\nsupervisor_conf/flask80.conf\n> 作为 supervisor 管理的子进程的配置文件，对 gunicorn 进程的一些管理。gunicorn 就是用来启动 flask web 程序的，示例如下。\n```bash\n[program:flask_app80]\n...\n...\n#flasktest就是代表flasktest.py，这里不写后缀。app是flasktest.py文件中设置的flask入口名\ncommand = /usr/local/bin/gunicorn -c /python/gconf80.py flasktest:app\nautostart = true #在supervisord启动的时候也自动启动\n...\n...\n```\nsupervisor_flaskapp.conf\n> 作为启动 supervisor 时的主配置文件，主配置文件中会引入 flask80.conf 子配置文件。\n\n\n### supervisor 管理进程\n\n> supervisor 的多进程管理，就类似于nginx 的多站点管理，每个站点一个配置文件，然后在nginx主配置文件中引用。\n- supervisor是一个进程管理系统，它通过fork/exec的方式将这些被管理的进程当作它的子进程来启动，若该子进程异常中断，则父进程可以准确地获取子进程异常中断的信息。\n- supervisor 可以通过 web 界面对进程进行启动、停止、重启操作\n\n以下是 nginx 进程的配置，示例参考\n```\n[program:nginx]\ncommand = /usr/local/bin/nginx -g 'daemon off;' -c /usr/local/etc/nginx/nginx.conf\nautostart = true\nstartsecs = 5\nautorestart = true\nstartretries = 3\nuser = root\n```\n### 安装 supervisor\n```shell\npip install supervisor\n#生成默认配置文件，运行如下命令\nmkdir -p /etc/supervisor\necho_supervisord_conf > /etc/supervisor/supervisord.conf #生成默认主配置文件\n```\n\n> /python/supervisor_flaskapp.conf\n\n> 这里需要说明一下,为什么把 /etc/supervisor/supervisord.conf 主配置文件引入到 supervisor_flaskapp.conf 中\n\n一般正常的操作是，启动 supervisor 使用的是主配置文件 supervisord.conf，并需要在主配置文件的结尾处修改引入路径，如下\n```\n[include]\nfiles = /python/supervisor_conf/*.conf\n```\n这里之所以在 supervisor_flaskapp.conf 中使用如下方式\n```\n[include]\nfiles = /etc/supervisor/supervisord.conf /python/supervisor_conf/*.conf\n```\n就是为了不修改 supervisord.conf 主配置文件的前提下，把主配置文件的内容引入到 /python/supervisor_flaskapp.conf 文件中，并把它作为启动 supervisor 使用的主配置文件。\n\n```shell\n#supervisor_flaskapp.conf 内容开始\n\n#这里 /python/supervisor_conf/*.conf 类似于 nginx 中配置文件的引用方式\n\n[include]\nfiles = /etc/supervisor/supervisord.conf /python/supervisor_conf/*.conf\n\n#你也可以在 /etc/supervisor/supervisord.conf 的底部，直接修改成如下\n#作如下修改后，启动 supervisor 时使用主配置文件 /etc/supervisor/supervisord.conf\n#[include]\n#files = /python/supervisor_conf/*.conf\n\n#web管理界面\n[inet_http_server]\nport = 0.0.0.0:8000\nusername = admin\npassword = admin\n\n#supervisor_flaskapp.conf 内容结束\n\n```\n> /python/supervisor_conf/flask80.conf\n\n```shell\n#flask80.conf 与 flask443.conf 不同之处\n#1、gunicorn 引入的参数配置文件不同 gconf443.py\n#2、[program:flask_app80]定义的程序名不同 flask_app443\n\n#flask80.conf 内容开始 \n\n#定义应用名称flask_app（一个配置文件中可以配置多个程序）\n[program:flask_app80]\n#创建该项目用户\nuser = root\n#应用目录 flasktest.py 所在的目录\ndirectory = /python\n\n#把gunicorn 的参数集中放入一个配置文件中(跟 nginx 启动一样，也是需要配置文件)\ncommand = /usr/local/bin/gunicorn -c /python/gconf80.py flasktest:app\nautostart = true #在supervisord启动的时候也自动启动\nautorestart = true #程序异常退出后自动重启\nstartsecs = 1 #自动重启间隔时间(秒)\n#进程启动失败后，最大尝试的次数。当超过3次后，supervisor将把此进程的状态置为FAIL\nstartretries = 3\nstopasgroup = true #确保关闭supervisord时停止所有相关子进程\nkillasgroup = true #确保关闭supervisord时停止所有相关子进程\nstdout_logfile = /python/logs/supervisor_80_out.log\nstderr_logfile = /python/logs/supervisor_80_err.log\n\n#flask80.conf 内容结束\n\n```\n\n### 启动 supervisord 进程\n```shell\n/usr/local/bin/supervisord -c /python/supervisor_flaskapp.conf\n```\n> 打开 supervisor 进程管理界面 ip:8000\n\n## gunicorn 与 supervisor 总结\n> gconf80.py 作为 gunicorn 的配置文件，进程\ngunicorn -c /python/gconf80.py flasktest:app\n\n> gunicorn 进程写在 supervisor 配置文件中，进程\nsupervisord -c /python/supervisor_flaskapp.conf\n\n> 所以 supervisord < gunicorn 套娃\n\n## supervisor 远程管理进程\n\n> http://www.supervisord.org/api.html\n\n### 项目目录结构\n```\n/\n-- python\n---- supervisor_monit\n------ monit.py\n------ gconf_monit.py\n---- templates\n------ monit.html\n---- asset\n------ css\n-------- css.css\n\n```\n### 监控程序\n> /python/supervisor_monit/monit.py\n\n```py\nfrom flask import Flask, render_template, url_for, request, jsonify, redirect\nfrom xmlrpc.client import ServerProxy\nimport signal\nimport os\n\napp = Flask(__name__,\n    template_folder='/python/supervisor_monit/templates',\n    static_folder='/python/supervisor_monit/asset',\n    static_url_path=\"/\",\n    )\n\n@app.route(\"/getenv\")\ndef index_getenv():\n    return os.getenv('ljs2') # gunicorn 配置文件中定义的变量\n\n# 字典形式\nserverDict = {\n    \"pyweb1\":{\n        \"host\":\"80.210.236.20\",\n        \"port\":\"8000\",\n        \"user\":\"admin\",\n        \"passwd\":\"admin\",\n    },\n    \"pyweb2\":{\n        \"host\":\"80.210.236.20\",\n        \"port\":\"8001\",\n        \"user\":\"admin\",\n        \"passwd\":\"admin\",\n    }\n}\n\ndef getUrlRpc(name, sdict):\n    r = sdict[name]\n    return \"http://\"+r[\"user\"]+\":\"+r[\"passwd\"]+\"@\"+r[\"host\"]+\":\"+r[\"port\"]+\"/RPC2\"\n\n#定义一个函数,把它传递给前端\ndef getAllInfo(title):\n    # 自定义函数获取rpc地址\n    url = getUrlRpc(title, serverDict)\n    server = ServerProxy(url)\n    return server.supervisor.getAllProcessInfo()\n\n# 为 getAllInfo 函数设置请求超时时长，超过自定义的时长，单位秒，则返回自定义内容\n# 为了防止长时间获取不到 getAllProcessInfo 返回的信息，导致出错\n# 使用 python 启动此监控程序时 会出错，所以只能用 gunicorn 启动监控\ndef getAllInfoTimeOut(n):\n    def handler(signum, frame):\n        raise AssertionError\n    try:\n        signal.signal(signal.SIGALRM, handler)\n        signal.alarm(10) # 设置超时时长，单位秒\n        return getAllInfo(n)\n    except AssertionError: # 错误类似为 AssertionError 时，执行\n        return []\n    except: # 当上面没有匹配的错误类似时，执行此条，放在最后\n        return []\n    finally: # 此代码段不能删除，虽然对页面没有影响，但是后台日志会输出错误\n        signal.alarm(0)\n        signal.signal(signal.SIGALRM, signal.SIG_DFL)\n\n@app.route(\"/\")\ndef index():\n    return render_template(\"monit.html\", envtest=os.getenv('ljs2'), sdict=serverDict, funAllInfo=getAllInfoTimeOut)\n\n# 重启 supervisor\n@app.route(\"/restartSupervisor\")\ndef restartSupervisor():\n    # 自定义函数获取rpc地址\n    title = request.args['title']\n    url = getUrlRpc(title,serverDict)\n    server = ServerProxy(url)\n    server.supervisor.restart()\n    return redirect(url_for('index',message=\"restartSupervisor_\"+title))\n\n# 开始或停止某个进程\n@app.route(\"/one.html\")\ndef index_one():\n    para = request.args['name']\n    method = request.args['method']\n    title = request.args['title']\n    # url = \"http://admin:admin@80.210.236.20:5002/RPC2\"\n    url = getUrlRpc(title,serverDict)\n    server = ServerProxy(url)\n    calls = [\n        {'methodName':method, 'params': [para]},\n        \n      ]\n\n    server.system.multicall(calls)\n    return redirect(url_for('index'))\n\n# 重启全部进程\n@app.route(\"/restartAll.html\")\ndef index_restartAll():\n    title = request.args['title']\n    # url = \"http://admin:admin@80.210.236.20:5002/RPC2\"\n    url = getUrlRpc(title,serverDict)\n    server = ServerProxy(url)\n    calls = [ \n        {'methodName':'supervisor.stopAllProcesses', 'params': []},\n        {'methodName':'supervisor.startAllProcesses', 'params': []},\n        \n      ]\n\n    server.system.multicall(calls)\n    return redirect(url_for('index'))\n\n# 重启某个进程\n@app.route(\"/restartOne.html\")\ndef index_restartOne():\n    para = request.args['name']\n    title = request.args['title']\n    # url = \"http://admin:admin@80.210.236.20:5002/RPC2\"\n    url = getUrlRpc(title,serverDict)\n    server = ServerProxy(url)\n    calls = [ \n        {'methodName':'supervisor.stopProcess', 'params': [para]},\n        {'methodName':'supervisor.startProcess', 'params': [para]},\n        \n      ]\n\n    server.system.multicall(calls)\n    return redirect(url_for('index'))\n\n#以下命令，只有在使用 python this.py 才起作用\nif __name__=='__main__':\n    app.run(debug=True,host='0.0.0.0',port=5000)\n\n```\n### 监控程序的模板文件\n> /python/supervisor_monit/templates/monit.html\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"refresh\" content=\"30;url={{ url_for('index') }}\">\n    <title>serverList</title>\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"{{ url_for('static', filename='css/css.css') }}\">\n</head>\n<body>\n{{ envtest }}\n<h1>supervisor列表 </h1>\n<ul>\n{% for sn in sdict %}\n    <h3>{{ sn }}@{{ sdict[sn][\"host\"] }}:{{ sdict[sn][\"port\"] }}--<a href=\"{{ url_for('restartSupervisor', title = sn) }}\">重启Supervisor</a></h3>\n    \n    {% if funAllInfo(sn) == [] %}\n    <li>此服务器不通，请检查设置！</li>\n    {% else %}\n    <li>\n        <a href=\"{{ url_for('index_one', method = 'supervisor.stopAllProcesses', name = '', title = sn) }}\">停止所有进程</a>\n\n        <a href=\"{{ url_for('index_one', method = 'supervisor.startAllProcesses', name = '', title = sn) }}\">启动所有进程</a>\n\n        <a href=\"{{ url_for('index_restartAll', title = sn) }}\">重启所有进程</a>\n    </li>\n    {% for snObj in funAllInfo(sn) %}\n    <li>{{ snObj[\"name\"] }}--{{ snObj[\"statename\"] }}--{{ snObj[\"description\"] }}\n        <a href=\"{{ url_for('index_one', method = 'supervisor.stopProcess', name = snObj['name'], title = sn) }}\">停止进程</a>\n        <a href=\"{{ url_for('index_one', method = 'supervisor.startProcess', name = snObj['name'], title = sn) }}\">启动进程</a>\n        <a href=\"{{ url_for('index_restartOne', name = snObj['name'], title = sn) }}\">重启进程</a>\n    </li>\n    {% endfor %}\n\n    {% endif %}\n    <hr/>\n{% endfor %}\n</ul>\n</body>\n</html>\n\n```\n### 监控程序的配置文件\n> /python/supervisor_monit/gconf_monit.py\n\n```py\n#gconf_monit.py\n\nfrom gevent import monkey\nmonkey.patch_all()\nimport multiprocessing\n\n# 注意：True, False 必须首字母大写\n\n#debug = True # 调试模式运行\n# gunicorn 守护进程，默认False(即不让其在后台运行，而是使用supervisor管理进程)\ndaemon = False\n# True，表示代码更新时将被热载入（修改代码后不用手动重启进程）。\n#如果是直接运行gunicorn命令，直接加参数 --reload 即可\nreload = True\n#绑定与Nginx通信的端口ipv4、ipv6\nbind = '0.0.0.0:5000'\n#bind = '[::]:5000'\n#workers = multiprocessing.cpu_count() # 根据计算的CPU数量设置进程数\nworkers = 1\nthreads = 1 #指定每个进程开启的线程数\n#默认为sync阻塞模式，最好选择gevent模式，需要安装gevent模块\n#Flask+gevent高效部署（基于gevent模块实现并发）\n#适用于io访问频繁的项目(比如对数据库的读写, 发送Http请求等等)，算法类型不适用\nworker_class = 'gevent'\n\n#设置环境变量(key=value)，将变量传递给flask\n'''\n# flask.py 中调用变量\nimport os\nos.getenv('ljs1')\n'''\nraw_env=[\"ljs1=111\",\"ljs2=bbb\"]\n\n#日志级别，这个日志级别指的是错误日志的级别，而访问日志的级别无法设置\nloglevel = 'info'\n\n#设置gunicorn访问日志格式，错误日志无法设置\naccess_log_format = '%(t)s %(p)s %(h)s \"%(r)s\" %(s)s %(L)s %(b)s %(f)s\" \"%(a)s\"'\n'''\n其每个选项的含义如下：\nh  remote address\nl  '-'\nu  currently '-', may be user name in future releases\nt  date of the request\nr  status line (e.g. ``GET / HTTP/1.1``)\ns  status\nb  response length or '-'\nf  referer\na  user agent\nT  request time in seconds\nD  request time in microseconds\nL  request time in decimal seconds\np  process ID\n'''\naccesslog = \"/python/logs/gunicorn_access_monit.log\" #访问日志文件\nerrorlog  = \"/python/logs/gunicorn_error_monit.log\" #错误日志文件\n\n#gconf_monit.py 内容结束\n\n```\n### 启动监控程序\n\n```shell\n# 当配置文件 gconf_monit.py 中未指定 chdir 时，\n# 需要进入 monit.py 所在的目录，不然会出现错误提示\n# ModuleNotFoundError: No module named 'monit'\ncd /python/supervisor_monit\ngunicorn -c /python/supervisor_monit/gconf_monit.py monit:app --preload\n```\n> 使用 ip:5000 查看监控\n\n## 附件\n> 其它 supervisor 命令\n```shell\n#启动、停止、重启应用、查看状态\nsupervisorctl start flask_app\nsupervisorctl stop flask_app\nsupervisorctl stop all #停止全部\nsupervisorctl restart flask_app # 重启，注意这里不会重新加载配置文件\nsupervisorctl status flask_app\nsupervisorctl status all\n\n#重启主进程 supervisord，重新加载配置文件，重新启动正在运行的所有程序\n# supervisord 进程的 pid 不会更新\nsupervisorctl reload\n\n#终止supervisord进程和被supervisord管理的子进程\n#如果gunicorn配置文件中daemon = False，则也会终止gunicorn\nsupervisorctl shutdown\n\nsupervisorctl reread && supervisorctl update\n\n#预读取配置(会检测配置文件，找出配置有改动的程序，并列出程序名)\n[root@localhost ~]# supervisorctl reread\nflask_app: changed\n\n#更新进程组:根据预读取的配置文件，启动新程序或重启配置有改动的程序\n#配置没有改动的程序不会受影响\n[root@localhost ~]# supervisorctl update\nflask_app: stopped\nflask_app: updated process group\n[root@localhost ~]# \n\n```","tags":["flask","supervisor","gunicorn"],"categories":["supervisor"]}]